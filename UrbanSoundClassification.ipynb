{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import keras.models\n",
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.io import wavfile as wav\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44100\n"
     ]
    }
   ],
   "source": [
    "# Import file\n",
    "sound_rate, sound_data = wav.read('Datasets/UrbanSoundClassification/fold1/7061-6-0-0.wav')\n",
    "# Play the signal\n",
    "print(sound_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sound_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print([x[0] for x in sound_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Zero crossing rage feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sign(number):\n",
    "  if number <= 0:\n",
    "    return -1\n",
    "  else:\n",
    "    return 1\n",
    "\n",
    "def get_zero_crossing_rate(sound):\n",
    "  total = len(sound)\n",
    "  # zero_crossing_num = 0\n",
    "  # for i in range(total - 1):\n",
    "  #   current_value_sign = get_sign(sound[i])\n",
    "  #   next_value_sign = get_sign(sound[i + 1])\n",
    "  #   if current_value_sign != next_value_sign:\n",
    "  #     zero_crossing_num += 1\n",
    "  # result = np.array([zero_crossing_num / (total - 1)])\n",
    "  # return result\n",
    "  zero_crossings = librosa.zero_crossings(sound, pad=False)\n",
    "  zcr_sum = np.sum(zero_crossings)\n",
    "  result = np.array([zcr_sum / (total - 1)])\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Duration feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def duration(input):\n",
    "    return np.array(input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Energy feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def root_mean_square_error(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# energia del segnale\n",
    "def energy(input):\n",
    "    return np.sum((input*1.0)**2, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def energy(input):\n",
    "#     if np.sum((input*1.0)**2, keepdims=True).shape[0] != 1:\n",
    "#         print(np.sum((input*1.0)**2, keepdims=True).shape)\n",
    "#     energy_data = np.sum((input*1.0)**2, keepdims=True)\n",
    "#     print(energy_data.shape)\n",
    "#     if type(energy_data[0]) != 'numpy.ndarray':\n",
    "#         return energy_data\n",
    "#     else:\n",
    "#         result = energy_data[0]\n",
    "#         if type(result[0]) != 'numpy.ndarray':\n",
    "#             return result\n",
    "#         else:\n",
    "#             while result.shape != (1,):\n",
    "#                 result = result[0]\n",
    "#             return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44100\n"
     ]
    }
   ],
   "source": [
    "# Import file\n",
    "sound_rate, sound_data = wav.read('Datasets/UrbanSoundClassification/fold1/157867-8-0-6.wav')\n",
    "# Play the signal\n",
    "print(sound_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "print(energy(sound_data).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### MFCCs features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feats_spectrogram(input, rate=2000, tsize=10):\n",
    "    trimmed_input = feats_temporal(input, rate)\n",
    "    X = librosa.stft(y=trimmed_input)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    return Xdb.flatten()\n",
    "\n",
    "\n",
    "def feats_mel(input, rate=2000, tsize=10):\n",
    "    trimmed_input = feats_temporal(input, rate)\n",
    "    X = librosa.feature.melspectrogram(y=trimmed_input, sr=rate)\n",
    "    S_DB = librosa.power_to_db(X, ref=np.max)\n",
    "    return S_DB.reshape(S_DB.shape[0] * S_DB.shape[1])\n",
    "\n",
    "\n",
    "def feats_mfcc(input, rate=2000, tsize=10):\n",
    "    trimmed_input = feats_temporal(input, rate)\n",
    "    X = librosa.feature.mfcc(y=trimmed_input, sr=rate)\n",
    "    return X.reshape(X.shape[0] * X.shape[1])\n",
    "\n",
    "def feats_temporal(input, size=2000):\n",
    "    # Remove any values exceeding the given limit\n",
    "    output = input[0:min(size, input.shape[0])]\n",
    "    # Add null values (padding) in order to reach the requested size\n",
    "    output = np.concatenate((output, np.zeros(size-output.shape[0])))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features(input, filename):\n",
    "    try:\n",
    "        return np.concatenate((energy(input), get_zero_crossing_rate(input), feats_spectrogram(input, 4000), feats_mel(input, 4000), feats_mfcc(input, 4000)))\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data loading\n",
    "from tqdm import tqdm\n",
    "def load_data(feature_extractor=get_features, normalize=False):\n",
    "    features = []\n",
    "    labels = []\n",
    "    x=0\n",
    "    for f in os.listdir('Datasets/UrbanSoundClassification/'):\n",
    "        for audio_file in tqdm(os.listdir('Datasets/UrbanSoundClassification/'+f)):\n",
    "            try:\n",
    "                if audio_file.endswith('.wav'):\n",
    "                    _, signal = wav.read('Datasets/UrbanSoundClassification/'+f+'/'+audio_file)\n",
    "                    if len(signal.shape) == 2:\n",
    "                        signal = np.asarray([x[0] for x in signal])\n",
    "                    file_features = get_features(signal, 'Datasets/UrbanSoundClassification/'+f+'/'+audio_file)\n",
    "                    features.append(file_features)\n",
    "                    label = audio_file.split('-')[1]\n",
    "                    labels.append(label)\n",
    "            except:\n",
    "                None\n",
    "\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=1)\n",
    "    if normalize:\n",
    "        eps = 0.001\n",
    "        x_train = np.array(x_train)\n",
    "        X_train_mean = x_train.mean(axis=0)\n",
    "        X_train_std = x_train.std(axis=0)\n",
    "        x_train = (x_train - X_train_mean + eps)/(X_train_std + eps)\n",
    "        x_train = [row for row in x_train]\n",
    "\n",
    "        x_test = [row for row in (np.array(x_test) - X_train_mean + eps)/(X_train_std + eps)]\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 873/873 [01:22<00:00, 10.62it/s]\n",
      "100%|██████████| 837/837 [01:00<00:00, 13.93it/s]\n",
      "100%|██████████| 888/888 [00:59<00:00, 15.03it/s]\n",
      "100%|██████████| 925/925 [00:59<00:00, 15.46it/s]\n",
      "100%|██████████| 990/990 [01:08<00:00, 14.38it/s]\n",
      "100%|██████████| 936/936 [00:58<00:00, 15.90it/s]\n",
      "100%|██████████| 823/823 [00:49<00:00, 16.66it/s]\n",
      "100%|██████████| 838/838 [00:55<00:00, 15.13it/s]\n",
      "100%|██████████| 806/806 [00:54<00:00, 14.88it/s]\n",
      "100%|██████████| 816/816 [00:54<00:00, 14.86it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = load_data(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7850"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('./Datasets/UrbanSoundClassification/processed', x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = np.load('./Datasets/UrbanSoundClassification/processed.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_list = [x.tolist() for x in dataset['x_train'] ]\n",
    "y_train_list =   [x.tolist() for x in dataset['y_train'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7850,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_list)\n",
    "len(y_train_list)\n",
    "dataset['x_train'].shape\n",
    "dataset['y_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 7639.468s\n"
     ]
    }
   ],
   "source": [
    "# Parameters to be tested in cross-validation\n",
    "param_grid = {'C': [100, 500, 1000],\n",
    "'gamma': [0.005, 0.01, 0.1, 0.5, 1.0], }\n",
    "\n",
    "# Support Vector Machine initialization\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid, cv=2)\n",
    "\n",
    "# Training\n",
    "t0 = time()\n",
    "clf = clf.fit(x_train_list, y_train_list)\n",
    "print('Training completed in %0.3fs' % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"shutdown /s /t 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test_list = [x.tolist() for x in dataset['x_test'] ]\n",
    "y_test_list = [x.tolist() for x in dataset['y_test'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        96\n",
      "           1       0.97      0.67      0.79        42\n",
      "           2       0.66      0.69      0.68       100\n",
      "           3       0.49      0.68      0.57        90\n",
      "           4       0.85      0.80      0.83       106\n",
      "           5       0.90      0.85      0.87       105\n",
      "           6       0.89      0.73      0.80        33\n",
      "           7       0.91      0.92      0.92       104\n",
      "           8       0.88      0.83      0.86       100\n",
      "           9       0.70      0.68      0.69        97\n",
      "\n",
      "    accuracy                           0.78       873\n",
      "   macro avg       0.81      0.77      0.79       873\n",
      "weighted avg       0.80      0.78      0.79       873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test_list)\n",
    "print(classification_report(y_test_list, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Prediction')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.xlabel('Ground truth')\n",
    "plt.ylabel('Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./Datasets/Classifiers/speech/svm1.pickle\", \"wb+\") as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./Datasets/Classifiers/speech/svm.pickle\", \"rb\") as f:\n",
    "    svm_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Multi layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "one_hot_train = to_categorical(dataset['y_train'])\n",
    "one_hot_test = to_categorical(dataset['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7850, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 4694)]            0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 512)               2403840   \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,576,970\n",
      "Trainable params: 2,576,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers, Input, Model\n",
    "from keras.layers import Dense, Dropout\n",
    "reg = regularizers.l2(0.001)\n",
    "input_layer = Input(shape=( 4694,))\n",
    "x = Dense(512, activation = 'relu', )(input_layer)\n",
    "# x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation = 'relu', )(x)\n",
    "# x = Dropout(0.4)(x)\n",
    "x = Dense(128, activation = 'relu', )(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation = 'relu', )(x)\n",
    "x = Dropout(0.1)(x)\n",
    "output = Dense(10, activation = \"softmax\")(x)\n",
    "\n",
    "model = Model(input_layer, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(873, 4694)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataset['x_train']\n",
    "test_data = dataset['x_test']\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "123/123 [==============================] - 2s 7ms/step - loss: 2.4578 - accuracy: 0.1915 - val_loss: 2.0575 - val_accuracy: 0.2589\n",
      "Epoch 2/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 2.0756 - accuracy: 0.2485 - val_loss: 1.9664 - val_accuracy: 0.2967\n",
      "Epoch 3/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.9854 - accuracy: 0.2799 - val_loss: 1.8049 - val_accuracy: 0.3276\n",
      "Epoch 4/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.9200 - accuracy: 0.3041 - val_loss: 1.8057 - val_accuracy: 0.3666\n",
      "Epoch 5/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.8773 - accuracy: 0.3178 - val_loss: 1.8270 - val_accuracy: 0.3333\n",
      "Epoch 6/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.8921 - accuracy: 0.3166 - val_loss: 1.6954 - val_accuracy: 0.3677\n",
      "Epoch 7/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.7850 - accuracy: 0.3552 - val_loss: 1.6466 - val_accuracy: 0.4215\n",
      "Epoch 8/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.7403 - accuracy: 0.3735 - val_loss: 1.6556 - val_accuracy: 0.3998\n",
      "Epoch 9/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.7199 - accuracy: 0.3828 - val_loss: 1.6660 - val_accuracy: 0.3918\n",
      "Epoch 10/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.6669 - accuracy: 0.4024 - val_loss: 1.5542 - val_accuracy: 0.4387\n",
      "Epoch 11/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.6636 - accuracy: 0.4051 - val_loss: 1.4910 - val_accuracy: 0.4834\n",
      "Epoch 12/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.6335 - accuracy: 0.4194 - val_loss: 1.5119 - val_accuracy: 0.4605\n",
      "Epoch 13/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.5572 - accuracy: 0.4448 - val_loss: 1.4454 - val_accuracy: 0.4822\n",
      "Epoch 14/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.5101 - accuracy: 0.4628 - val_loss: 1.4424 - val_accuracy: 0.4822\n",
      "Epoch 15/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.5458 - accuracy: 0.4571 - val_loss: 1.4785 - val_accuracy: 0.4708\n",
      "Epoch 16/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.4944 - accuracy: 0.4651 - val_loss: 1.3859 - val_accuracy: 0.5246\n",
      "Epoch 17/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.4173 - accuracy: 0.4971 - val_loss: 1.4442 - val_accuracy: 0.5178\n",
      "Epoch 18/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.4196 - accuracy: 0.4982 - val_loss: 1.3739 - val_accuracy: 0.5521\n",
      "Epoch 19/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.4072 - accuracy: 0.5055 - val_loss: 1.3159 - val_accuracy: 0.5269\n",
      "Epoch 20/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.4007 - accuracy: 0.5080 - val_loss: 1.3290 - val_accuracy: 0.5544\n",
      "Epoch 21/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.3462 - accuracy: 0.5222 - val_loss: 1.2406 - val_accuracy: 0.5750\n",
      "Epoch 22/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.2974 - accuracy: 0.5377 - val_loss: 1.2952 - val_accuracy: 0.5682\n",
      "Epoch 23/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.3082 - accuracy: 0.5404 - val_loss: 1.3074 - val_accuracy: 0.5315\n",
      "Epoch 24/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.2269 - accuracy: 0.5698 - val_loss: 1.2269 - val_accuracy: 0.5704\n",
      "Epoch 25/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.2286 - accuracy: 0.5651 - val_loss: 1.2352 - val_accuracy: 0.5670\n",
      "Epoch 26/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.1952 - accuracy: 0.5722 - val_loss: 1.1976 - val_accuracy: 0.6105\n",
      "Epoch 27/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.1977 - accuracy: 0.5782 - val_loss: 1.2041 - val_accuracy: 0.5945\n",
      "Epoch 28/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.1720 - accuracy: 0.5857 - val_loss: 1.2509 - val_accuracy: 0.5819\n",
      "Epoch 29/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.1811 - accuracy: 0.5871 - val_loss: 1.1856 - val_accuracy: 0.6208\n",
      "Epoch 30/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.1678 - accuracy: 0.5884 - val_loss: 1.1967 - val_accuracy: 0.5922\n",
      "Epoch 31/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.1242 - accuracy: 0.6013 - val_loss: 1.1680 - val_accuracy: 0.6186\n",
      "Epoch 32/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.6135 - val_loss: 1.1426 - val_accuracy: 0.6037\n",
      "Epoch 33/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 1.0612 - accuracy: 0.6204 - val_loss: 1.1174 - val_accuracy: 0.6197\n",
      "Epoch 34/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.0733 - accuracy: 0.6173 - val_loss: 1.1634 - val_accuracy: 0.6163\n",
      "Epoch 35/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.0288 - accuracy: 0.6302 - val_loss: 1.0969 - val_accuracy: 0.6334\n",
      "Epoch 36/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.0274 - accuracy: 0.6348 - val_loss: 1.1534 - val_accuracy: 0.6163\n",
      "Epoch 37/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.0409 - accuracy: 0.6331 - val_loss: 1.2158 - val_accuracy: 0.6048\n",
      "Epoch 38/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.0264 - accuracy: 0.6357 - val_loss: 1.0882 - val_accuracy: 0.6334\n",
      "Epoch 39/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 1.0162 - accuracy: 0.6442 - val_loss: 1.0546 - val_accuracy: 0.6506\n",
      "Epoch 40/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.9744 - accuracy: 0.6582 - val_loss: 1.0940 - val_accuracy: 0.6552\n",
      "Epoch 41/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.9857 - accuracy: 0.6527 - val_loss: 1.2450 - val_accuracy: 0.6002\n",
      "Epoch 42/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.9827 - accuracy: 0.6532 - val_loss: 1.0491 - val_accuracy: 0.6690\n",
      "Epoch 43/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.9197 - accuracy: 0.6801 - val_loss: 1.0728 - val_accuracy: 0.6277\n",
      "Epoch 44/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.9745 - accuracy: 0.6586 - val_loss: 1.1880 - val_accuracy: 0.6014\n",
      "Epoch 45/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.9559 - accuracy: 0.6633 - val_loss: 1.1463 - val_accuracy: 0.6220\n",
      "Epoch 46/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.8787 - accuracy: 0.6901 - val_loss: 1.1206 - val_accuracy: 0.6334\n",
      "Epoch 47/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.9086 - accuracy: 0.6801 - val_loss: 1.1055 - val_accuracy: 0.6277\n",
      "Epoch 48/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.8565 - accuracy: 0.6963 - val_loss: 1.0739 - val_accuracy: 0.6781\n",
      "Epoch 49/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.8659 - accuracy: 0.6931 - val_loss: 1.0055 - val_accuracy: 0.6621\n",
      "Epoch 50/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.8516 - accuracy: 0.7009 - val_loss: 1.1095 - val_accuracy: 0.6426\n",
      "Epoch 51/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.8377 - accuracy: 0.7034 - val_loss: 1.0539 - val_accuracy: 0.6804\n",
      "Epoch 52/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.8217 - accuracy: 0.7061 - val_loss: 1.0307 - val_accuracy: 0.6747\n",
      "Epoch 53/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.8219 - accuracy: 0.7135 - val_loss: 1.0731 - val_accuracy: 0.6735\n",
      "Epoch 54/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.8224 - accuracy: 0.7082 - val_loss: 1.0654 - val_accuracy: 0.6564\n",
      "Epoch 55/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.8132 - accuracy: 0.7096 - val_loss: 1.0682 - val_accuracy: 0.6758\n",
      "Epoch 56/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.8205 - accuracy: 0.7078 - val_loss: 1.2851 - val_accuracy: 0.6174\n",
      "Epoch 57/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.8029 - accuracy: 0.7139 - val_loss: 1.0777 - val_accuracy: 0.6747\n",
      "Epoch 58/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.7782 - accuracy: 0.7234 - val_loss: 1.1024 - val_accuracy: 0.6701\n",
      "Epoch 59/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.7852 - accuracy: 0.7293 - val_loss: 1.1001 - val_accuracy: 0.6712\n",
      "Epoch 60/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.7713 - accuracy: 0.7243 - val_loss: 1.1473 - val_accuracy: 0.6770\n",
      "Epoch 61/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.7497 - accuracy: 0.7335 - val_loss: 1.1007 - val_accuracy: 0.6724\n",
      "Epoch 62/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.7650 - accuracy: 0.7302 - val_loss: 1.0554 - val_accuracy: 0.6793\n",
      "Epoch 63/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.7473 - accuracy: 0.7376 - val_loss: 1.0403 - val_accuracy: 0.6758\n",
      "Epoch 64/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.7370 - accuracy: 0.7363 - val_loss: 1.1264 - val_accuracy: 0.6827\n",
      "Epoch 65/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.7548 - val_loss: 1.0176 - val_accuracy: 0.6838\n",
      "Epoch 66/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.7233 - accuracy: 0.7418 - val_loss: 1.2406 - val_accuracy: 0.6438\n",
      "Epoch 67/800\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.7151 - accuracy: 0.7468 - val_loss: 1.0755 - val_accuracy: 0.6953\n",
      "Epoch 68/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.6830 - accuracy: 0.7573 - val_loss: 1.1132 - val_accuracy: 0.6999\n",
      "Epoch 69/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.7245 - accuracy: 0.7454 - val_loss: 1.1334 - val_accuracy: 0.6655\n",
      "Epoch 70/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.6907 - accuracy: 0.7576 - val_loss: 1.1327 - val_accuracy: 0.6758\n",
      "Epoch 71/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.7144 - accuracy: 0.7525 - val_loss: 0.9981 - val_accuracy: 0.6919\n",
      "Epoch 72/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.6991 - accuracy: 0.7525 - val_loss: 1.1223 - val_accuracy: 0.6907\n",
      "Epoch 73/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.7251 - accuracy: 0.7489 - val_loss: 1.0769 - val_accuracy: 0.7102\n",
      "Epoch 74/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.6636 - accuracy: 0.7647 - val_loss: 1.1266 - val_accuracy: 0.7022\n",
      "Epoch 75/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.6406 - accuracy: 0.7698 - val_loss: 0.9965 - val_accuracy: 0.6964\n",
      "Epoch 76/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.7738 - val_loss: 1.1788 - val_accuracy: 0.6930\n",
      "Epoch 77/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.6505 - accuracy: 0.7758 - val_loss: 1.1374 - val_accuracy: 0.6919\n",
      "Epoch 78/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.6218 - accuracy: 0.7755 - val_loss: 1.1111 - val_accuracy: 0.6987\n",
      "Epoch 79/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.6218 - accuracy: 0.7797 - val_loss: 1.2148 - val_accuracy: 0.6953\n",
      "Epoch 80/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.6219 - accuracy: 0.7806 - val_loss: 1.1178 - val_accuracy: 0.7090\n",
      "Epoch 81/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.6284 - accuracy: 0.7817 - val_loss: 1.0489 - val_accuracy: 0.6907\n",
      "Epoch 82/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.7820 - val_loss: 1.0009 - val_accuracy: 0.7056\n",
      "Epoch 83/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.7734 - val_loss: 1.2903 - val_accuracy: 0.6919\n",
      "Epoch 84/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.7763 - val_loss: 0.9592 - val_accuracy: 0.7159\n",
      "Epoch 85/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.7920 - val_loss: 1.1101 - val_accuracy: 0.6987\n",
      "Epoch 86/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.7916 - val_loss: 1.0932 - val_accuracy: 0.7182\n",
      "Epoch 87/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.5717 - accuracy: 0.7971 - val_loss: 1.0495 - val_accuracy: 0.7136\n",
      "Epoch 88/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.7958 - val_loss: 1.0282 - val_accuracy: 0.7102\n",
      "Epoch 89/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7950 - val_loss: 1.0500 - val_accuracy: 0.7045\n",
      "Epoch 90/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.7989 - val_loss: 1.1227 - val_accuracy: 0.6953\n",
      "Epoch 91/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5992 - accuracy: 0.7856 - val_loss: 1.0135 - val_accuracy: 0.6999\n",
      "Epoch 92/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.7973 - val_loss: 1.1684 - val_accuracy: 0.6976\n",
      "Epoch 93/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.8150 - val_loss: 1.2110 - val_accuracy: 0.7171\n",
      "Epoch 94/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.7983 - val_loss: 1.0446 - val_accuracy: 0.7262\n",
      "Epoch 95/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.8101 - val_loss: 0.9921 - val_accuracy: 0.7171\n",
      "Epoch 96/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.5599 - accuracy: 0.7976 - val_loss: 1.0886 - val_accuracy: 0.7205\n",
      "Epoch 97/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.5359 - accuracy: 0.8071 - val_loss: 1.2488 - val_accuracy: 0.6999\n",
      "Epoch 98/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.5275 - accuracy: 0.8148 - val_loss: 0.9898 - val_accuracy: 0.7377\n",
      "Epoch 99/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.8092 - val_loss: 1.0152 - val_accuracy: 0.7148\n",
      "Epoch 100/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.5761 - accuracy: 0.7990 - val_loss: 1.1355 - val_accuracy: 0.7251\n",
      "Epoch 101/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.5165 - accuracy: 0.8205 - val_loss: 0.9910 - val_accuracy: 0.7411\n",
      "Epoch 102/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.8222 - val_loss: 1.0656 - val_accuracy: 0.7182\n",
      "Epoch 103/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.8255 - val_loss: 1.0551 - val_accuracy: 0.7320\n",
      "Epoch 104/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.8097 - val_loss: 1.0293 - val_accuracy: 0.7194\n",
      "Epoch 105/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.8150 - val_loss: 1.0344 - val_accuracy: 0.7354\n",
      "Epoch 106/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.8241 - val_loss: 1.0346 - val_accuracy: 0.7216\n",
      "Epoch 107/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.8215 - val_loss: 1.0314 - val_accuracy: 0.7171\n",
      "Epoch 108/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.8301 - val_loss: 1.3069 - val_accuracy: 0.6575\n",
      "Epoch 109/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.8192 - val_loss: 1.1570 - val_accuracy: 0.6953\n",
      "Epoch 110/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.4884 - accuracy: 0.8247 - val_loss: 1.0577 - val_accuracy: 0.7274\n",
      "Epoch 111/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.8334 - val_loss: 1.1092 - val_accuracy: 0.6816\n",
      "Epoch 112/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.8306 - val_loss: 1.1144 - val_accuracy: 0.7251\n",
      "Epoch 113/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.8326 - val_loss: 1.1240 - val_accuracy: 0.7457\n",
      "Epoch 114/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.8339 - val_loss: 1.1286 - val_accuracy: 0.7365\n",
      "Epoch 115/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.8362 - val_loss: 1.0623 - val_accuracy: 0.7308\n",
      "Epoch 116/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.8425 - val_loss: 1.1033 - val_accuracy: 0.7308\n",
      "Epoch 117/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.8288 - val_loss: 1.1393 - val_accuracy: 0.7400\n",
      "Epoch 118/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.8345 - val_loss: 1.1510 - val_accuracy: 0.7228\n",
      "Epoch 119/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.8269 - val_loss: 1.0472 - val_accuracy: 0.7171\n",
      "Epoch 120/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.8390 - val_loss: 1.1470 - val_accuracy: 0.7446\n",
      "Epoch 121/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.8403 - val_loss: 1.0908 - val_accuracy: 0.7182\n",
      "Epoch 122/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8581 - val_loss: 1.0943 - val_accuracy: 0.7388\n",
      "Epoch 123/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.8462 - val_loss: 1.1219 - val_accuracy: 0.7434\n",
      "Epoch 124/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.8459 - val_loss: 1.0877 - val_accuracy: 0.7285\n",
      "Epoch 125/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.8428 - val_loss: 1.1491 - val_accuracy: 0.7285\n",
      "Epoch 126/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8447 - val_loss: 1.0422 - val_accuracy: 0.7446\n",
      "Epoch 127/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.8494 - val_loss: 1.1549 - val_accuracy: 0.7228\n",
      "Epoch 128/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8527 - val_loss: 1.2164 - val_accuracy: 0.7320\n",
      "Epoch 129/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.8506 - val_loss: 1.0801 - val_accuracy: 0.7491\n",
      "Epoch 130/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8529 - val_loss: 1.0549 - val_accuracy: 0.7560\n",
      "Epoch 131/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.8413 - val_loss: 1.2994 - val_accuracy: 0.7194\n",
      "Epoch 132/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.8540 - val_loss: 1.0299 - val_accuracy: 0.7182\n",
      "Epoch 133/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8696 - val_loss: 1.0910 - val_accuracy: 0.7503\n",
      "Epoch 134/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8599 - val_loss: 1.1092 - val_accuracy: 0.7480\n",
      "Epoch 135/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.3784 - accuracy: 0.8690 - val_loss: 1.3321 - val_accuracy: 0.7216\n",
      "Epoch 136/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8620 - val_loss: 1.2917 - val_accuracy: 0.7365\n",
      "Epoch 137/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8521 - val_loss: 1.0683 - val_accuracy: 0.7354\n",
      "Epoch 138/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8652 - val_loss: 1.0386 - val_accuracy: 0.7285\n",
      "Epoch 139/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8550 - val_loss: 1.0883 - val_accuracy: 0.7377\n",
      "Epoch 140/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3661 - accuracy: 0.8716 - val_loss: 1.3200 - val_accuracy: 0.7320\n",
      "Epoch 141/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.4354 - accuracy: 0.8569 - val_loss: 1.1785 - val_accuracy: 0.7652\n",
      "Epoch 142/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3939 - accuracy: 0.8636 - val_loss: 1.0909 - val_accuracy: 0.7205\n",
      "Epoch 143/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.4355 - accuracy: 0.8580 - val_loss: 1.2684 - val_accuracy: 0.7194\n",
      "Epoch 144/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.4225 - accuracy: 0.8564 - val_loss: 1.0519 - val_accuracy: 0.7205\n",
      "Epoch 145/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3689 - accuracy: 0.8725 - val_loss: 1.3228 - val_accuracy: 0.7320\n",
      "Epoch 146/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3418 - accuracy: 0.8803 - val_loss: 1.1487 - val_accuracy: 0.7480\n",
      "Epoch 147/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.4065 - accuracy: 0.8631 - val_loss: 1.2364 - val_accuracy: 0.7400\n",
      "Epoch 148/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3704 - accuracy: 0.8734 - val_loss: 1.2106 - val_accuracy: 0.7274\n",
      "Epoch 149/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3867 - accuracy: 0.8646 - val_loss: 1.2170 - val_accuracy: 0.7434\n",
      "Epoch 150/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3537 - accuracy: 0.8767 - val_loss: 1.2828 - val_accuracy: 0.7491\n",
      "Epoch 151/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3985 - accuracy: 0.8633 - val_loss: 1.1308 - val_accuracy: 0.7285\n",
      "Epoch 152/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.3642 - accuracy: 0.8755 - val_loss: 1.3021 - val_accuracy: 0.7434\n",
      "Epoch 153/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8657 - val_loss: 1.2690 - val_accuracy: 0.7331\n",
      "Epoch 154/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.3587 - accuracy: 0.8801 - val_loss: 1.2827 - val_accuracy: 0.7331\n",
      "Epoch 155/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3294 - accuracy: 0.8869 - val_loss: 1.2737 - val_accuracy: 0.7675\n",
      "Epoch 156/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3656 - accuracy: 0.8800 - val_loss: 1.2499 - val_accuracy: 0.7537\n",
      "Epoch 157/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3633 - accuracy: 0.8782 - val_loss: 1.3255 - val_accuracy: 0.7102\n",
      "Epoch 158/800\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.3463 - accuracy: 0.8831 - val_loss: 1.2049 - val_accuracy: 0.7297\n",
      "Epoch 159/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2944 - accuracy: 0.8995 - val_loss: 1.2958 - val_accuracy: 0.7652\n",
      "Epoch 160/800\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.3752 - accuracy: 0.8736 - val_loss: 1.1653 - val_accuracy: 0.7434\n",
      "Epoch 161/800\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.3532 - accuracy: 0.8825 - val_loss: 1.1197 - val_accuracy: 0.7606\n",
      "Epoch 162/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3029 - accuracy: 0.8978 - val_loss: 1.2978 - val_accuracy: 0.7102\n",
      "Epoch 163/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3621 - accuracy: 0.8775 - val_loss: 1.3150 - val_accuracy: 0.7159\n",
      "Epoch 164/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3213 - accuracy: 0.8884 - val_loss: 1.1297 - val_accuracy: 0.7549\n",
      "Epoch 165/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3376 - accuracy: 0.8870 - val_loss: 1.1525 - val_accuracy: 0.7503\n",
      "Epoch 166/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3365 - accuracy: 0.8828 - val_loss: 1.4013 - val_accuracy: 0.7446\n",
      "Epoch 167/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3561 - accuracy: 0.8783 - val_loss: 1.1985 - val_accuracy: 0.7709\n",
      "Epoch 168/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3425 - accuracy: 0.8829 - val_loss: 1.1403 - val_accuracy: 0.7595\n",
      "Epoch 169/800\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.3319 - accuracy: 0.8902 - val_loss: 1.2793 - val_accuracy: 0.7423\n",
      "Epoch 170/800\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.2985 - accuracy: 0.8961 - val_loss: 1.3783 - val_accuracy: 0.7457\n",
      "Epoch 171/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3179 - accuracy: 0.8906 - val_loss: 1.2363 - val_accuracy: 0.7595\n",
      "Epoch 172/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3110 - accuracy: 0.8962 - val_loss: 1.2285 - val_accuracy: 0.7377\n",
      "Epoch 173/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3685 - accuracy: 0.8761 - val_loss: 1.2570 - val_accuracy: 0.7377\n",
      "Epoch 174/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3179 - accuracy: 0.8870 - val_loss: 1.2488 - val_accuracy: 0.7675\n",
      "Epoch 175/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3281 - accuracy: 0.8918 - val_loss: 1.2696 - val_accuracy: 0.7549\n",
      "Epoch 176/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3339 - accuracy: 0.8901 - val_loss: 1.3088 - val_accuracy: 0.7480\n",
      "Epoch 177/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.3578 - accuracy: 0.8825 - val_loss: 1.3463 - val_accuracy: 0.7446\n",
      "Epoch 178/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3072 - accuracy: 0.8986 - val_loss: 1.1213 - val_accuracy: 0.7801\n",
      "Epoch 179/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.8985 - val_loss: 1.3532 - val_accuracy: 0.7434\n",
      "Epoch 180/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2976 - accuracy: 0.8997 - val_loss: 1.3139 - val_accuracy: 0.7354\n",
      "Epoch 181/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2846 - accuracy: 0.9039 - val_loss: 1.3291 - val_accuracy: 0.7595\n",
      "Epoch 182/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8862 - val_loss: 1.3668 - val_accuracy: 0.7411\n",
      "Epoch 183/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.3314 - accuracy: 0.8918 - val_loss: 1.4612 - val_accuracy: 0.7331\n",
      "Epoch 184/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8762 - val_loss: 1.5901 - val_accuracy: 0.7308\n",
      "Epoch 185/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3074 - accuracy: 0.8962 - val_loss: 1.3435 - val_accuracy: 0.7514\n",
      "Epoch 186/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3013 - accuracy: 0.8985 - val_loss: 1.4081 - val_accuracy: 0.7285\n",
      "Epoch 187/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2907 - accuracy: 0.9024 - val_loss: 1.4546 - val_accuracy: 0.7491\n",
      "Epoch 188/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.3198 - accuracy: 0.8921 - val_loss: 1.2507 - val_accuracy: 0.7491\n",
      "Epoch 189/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.8932 - val_loss: 1.1565 - val_accuracy: 0.7732\n",
      "Epoch 190/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2761 - accuracy: 0.9074 - val_loss: 1.2078 - val_accuracy: 0.7812\n",
      "Epoch 191/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2832 - accuracy: 0.9041 - val_loss: 1.2295 - val_accuracy: 0.7663\n",
      "Epoch 192/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8930 - val_loss: 1.2455 - val_accuracy: 0.7595\n",
      "Epoch 193/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2884 - accuracy: 0.9008 - val_loss: 1.2692 - val_accuracy: 0.7675\n",
      "Epoch 194/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3094 - accuracy: 0.8958 - val_loss: 1.5101 - val_accuracy: 0.7159\n",
      "Epoch 195/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8894 - val_loss: 1.3073 - val_accuracy: 0.7400\n",
      "Epoch 196/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.9085 - val_loss: 1.2683 - val_accuracy: 0.7606\n",
      "Epoch 197/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2589 - accuracy: 0.9135 - val_loss: 1.3343 - val_accuracy: 0.7400\n",
      "Epoch 198/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.9056 - val_loss: 1.6231 - val_accuracy: 0.6919\n",
      "Epoch 199/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2980 - accuracy: 0.9009 - val_loss: 1.2366 - val_accuracy: 0.7503\n",
      "Epoch 200/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2981 - accuracy: 0.9025 - val_loss: 1.5032 - val_accuracy: 0.7526\n",
      "Epoch 201/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3305 - accuracy: 0.8918 - val_loss: 1.5034 - val_accuracy: 0.7400\n",
      "Epoch 202/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2912 - accuracy: 0.9036 - val_loss: 1.2786 - val_accuracy: 0.7411\n",
      "Epoch 203/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2671 - accuracy: 0.9120 - val_loss: 1.3262 - val_accuracy: 0.7606\n",
      "Epoch 204/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2572 - accuracy: 0.9148 - val_loss: 1.2646 - val_accuracy: 0.7686\n",
      "Epoch 205/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3129 - accuracy: 0.8968 - val_loss: 1.3544 - val_accuracy: 0.7480\n",
      "Epoch 206/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3149 - accuracy: 0.8976 - val_loss: 1.3005 - val_accuracy: 0.7732\n",
      "Epoch 207/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2570 - accuracy: 0.9140 - val_loss: 1.4674 - val_accuracy: 0.7663\n",
      "Epoch 208/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2658 - accuracy: 0.9084 - val_loss: 1.3785 - val_accuracy: 0.7595\n",
      "Epoch 209/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3117 - accuracy: 0.8986 - val_loss: 1.1884 - val_accuracy: 0.7480\n",
      "Epoch 210/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2958 - accuracy: 0.8978 - val_loss: 1.2254 - val_accuracy: 0.7652\n",
      "Epoch 211/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2522 - accuracy: 0.9130 - val_loss: 1.3407 - val_accuracy: 0.7549\n",
      "Epoch 212/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2409 - accuracy: 0.9183 - val_loss: 1.3213 - val_accuracy: 0.7514\n",
      "Epoch 213/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.9052 - val_loss: 1.2983 - val_accuracy: 0.7514\n",
      "Epoch 214/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3265 - accuracy: 0.8952 - val_loss: 1.3306 - val_accuracy: 0.7503\n",
      "Epoch 215/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2574 - accuracy: 0.9143 - val_loss: 1.1863 - val_accuracy: 0.7663\n",
      "Epoch 216/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2324 - accuracy: 0.9238 - val_loss: 1.3832 - val_accuracy: 0.7732\n",
      "Epoch 217/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2399 - accuracy: 0.9176 - val_loss: 1.1670 - val_accuracy: 0.7617\n",
      "Epoch 218/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2863 - accuracy: 0.9064 - val_loss: 1.3690 - val_accuracy: 0.7411\n",
      "Epoch 219/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8874 - val_loss: 1.3172 - val_accuracy: 0.7629\n",
      "Epoch 220/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2660 - accuracy: 0.9098 - val_loss: 1.4292 - val_accuracy: 0.7629\n",
      "Epoch 221/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2584 - accuracy: 0.9125 - val_loss: 1.2034 - val_accuracy: 0.7663\n",
      "Epoch 222/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2649 - accuracy: 0.9126 - val_loss: 1.5436 - val_accuracy: 0.7526\n",
      "Epoch 223/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2587 - accuracy: 0.9171 - val_loss: 1.2856 - val_accuracy: 0.7663\n",
      "Epoch 224/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2614 - accuracy: 0.9108 - val_loss: 1.5341 - val_accuracy: 0.7537\n",
      "Epoch 225/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3194 - accuracy: 0.9020 - val_loss: 1.3665 - val_accuracy: 0.7400\n",
      "Epoch 226/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2992 - accuracy: 0.9033 - val_loss: 1.1949 - val_accuracy: 0.7583\n",
      "Epoch 227/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2388 - accuracy: 0.9208 - val_loss: 1.3081 - val_accuracy: 0.7755\n",
      "Epoch 228/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2409 - accuracy: 0.9204 - val_loss: 1.4298 - val_accuracy: 0.7377\n",
      "Epoch 229/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2732 - accuracy: 0.9098 - val_loss: 1.3721 - val_accuracy: 0.7308\n",
      "Epoch 230/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3392 - accuracy: 0.8948 - val_loss: 1.2899 - val_accuracy: 0.7537\n",
      "Epoch 231/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2445 - accuracy: 0.9225 - val_loss: 1.3625 - val_accuracy: 0.7400\n",
      "Epoch 232/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2459 - accuracy: 0.9163 - val_loss: 1.4963 - val_accuracy: 0.7423\n",
      "Epoch 233/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2625 - accuracy: 0.9136 - val_loss: 1.5174 - val_accuracy: 0.7434\n",
      "Epoch 234/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2454 - accuracy: 0.9206 - val_loss: 1.4015 - val_accuracy: 0.7732\n",
      "Epoch 235/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2360 - accuracy: 0.9243 - val_loss: 1.3598 - val_accuracy: 0.7457\n",
      "Epoch 236/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2270 - accuracy: 0.9205 - val_loss: 1.3224 - val_accuracy: 0.7468\n",
      "Epoch 237/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2644 - accuracy: 0.9115 - val_loss: 1.4267 - val_accuracy: 0.7365\n",
      "Epoch 238/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2766 - accuracy: 0.9097 - val_loss: 1.2562 - val_accuracy: 0.7652\n",
      "Epoch 239/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2301 - accuracy: 0.9222 - val_loss: 1.5272 - val_accuracy: 0.7778\n",
      "Epoch 240/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2646 - accuracy: 0.9148 - val_loss: 1.4506 - val_accuracy: 0.7503\n",
      "Epoch 241/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2710 - accuracy: 0.9103 - val_loss: 1.2668 - val_accuracy: 0.7526\n",
      "Epoch 242/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2125 - accuracy: 0.9271 - val_loss: 1.4882 - val_accuracy: 0.7526\n",
      "Epoch 243/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2711 - accuracy: 0.9173 - val_loss: 1.4377 - val_accuracy: 0.7514\n",
      "Epoch 244/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2677 - accuracy: 0.9154 - val_loss: 1.1878 - val_accuracy: 0.7755\n",
      "Epoch 245/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2354 - accuracy: 0.9219 - val_loss: 1.3029 - val_accuracy: 0.7835\n",
      "Epoch 246/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2247 - accuracy: 0.9265 - val_loss: 1.4618 - val_accuracy: 0.7537\n",
      "Epoch 247/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2984 - accuracy: 0.9043 - val_loss: 1.5742 - val_accuracy: 0.7434\n",
      "Epoch 248/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2786 - accuracy: 0.9144 - val_loss: 1.4039 - val_accuracy: 0.7686\n",
      "Epoch 249/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.3025 - accuracy: 0.9073 - val_loss: 1.3275 - val_accuracy: 0.7629\n",
      "Epoch 250/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2419 - accuracy: 0.9206 - val_loss: 1.3491 - val_accuracy: 0.7549\n",
      "Epoch 251/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2737 - accuracy: 0.9127 - val_loss: 1.3978 - val_accuracy: 0.7377\n",
      "Epoch 252/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2313 - accuracy: 0.9246 - val_loss: 1.3392 - val_accuracy: 0.7457\n",
      "Epoch 253/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2479 - accuracy: 0.9169 - val_loss: 1.1449 - val_accuracy: 0.7847\n",
      "Epoch 254/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1896 - accuracy: 0.9408 - val_loss: 1.2933 - val_accuracy: 0.7595\n",
      "Epoch 255/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2060 - accuracy: 0.9344 - val_loss: 1.3272 - val_accuracy: 0.7778\n",
      "Epoch 256/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2454 - accuracy: 0.9239 - val_loss: 1.3922 - val_accuracy: 0.7308\n",
      "Epoch 257/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2535 - accuracy: 0.9178 - val_loss: 1.2489 - val_accuracy: 0.7801\n",
      "Epoch 258/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2271 - accuracy: 0.9237 - val_loss: 1.3433 - val_accuracy: 0.7709\n",
      "Epoch 259/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2476 - accuracy: 0.9168 - val_loss: 1.4239 - val_accuracy: 0.7572\n",
      "Epoch 260/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2212 - accuracy: 0.9238 - val_loss: 1.4808 - val_accuracy: 0.7629\n",
      "Epoch 261/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2271 - accuracy: 0.9273 - val_loss: 1.3498 - val_accuracy: 0.7721\n",
      "Epoch 262/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2650 - accuracy: 0.9192 - val_loss: 1.4420 - val_accuracy: 0.7732\n",
      "Epoch 263/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2508 - accuracy: 0.9187 - val_loss: 1.6271 - val_accuracy: 0.7239\n",
      "Epoch 264/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2467 - accuracy: 0.9190 - val_loss: 1.3371 - val_accuracy: 0.7721\n",
      "Epoch 265/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2553 - accuracy: 0.9180 - val_loss: 1.4550 - val_accuracy: 0.7640\n",
      "Epoch 266/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2362 - accuracy: 0.9245 - val_loss: 1.2684 - val_accuracy: 0.7881\n",
      "Epoch 267/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2347 - accuracy: 0.9200 - val_loss: 1.3586 - val_accuracy: 0.7709\n",
      "Epoch 268/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2855 - accuracy: 0.9107 - val_loss: 1.4114 - val_accuracy: 0.7595\n",
      "Epoch 269/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2341 - accuracy: 0.9236 - val_loss: 1.5308 - val_accuracy: 0.7377\n",
      "Epoch 270/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2193 - accuracy: 0.9279 - val_loss: 1.2977 - val_accuracy: 0.7743\n",
      "Epoch 271/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2118 - accuracy: 0.9303 - val_loss: 1.4614 - val_accuracy: 0.7583\n",
      "Epoch 272/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2126 - accuracy: 0.9320 - val_loss: 1.4630 - val_accuracy: 0.7595\n",
      "Epoch 273/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2218 - accuracy: 0.9332 - val_loss: 1.4479 - val_accuracy: 0.7698\n",
      "Epoch 274/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2480 - accuracy: 0.9225 - val_loss: 1.5806 - val_accuracy: 0.7446\n",
      "Epoch 275/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2309 - accuracy: 0.9232 - val_loss: 1.5535 - val_accuracy: 0.7778\n",
      "Epoch 276/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2393 - accuracy: 0.9219 - val_loss: 1.3048 - val_accuracy: 0.7766\n",
      "Epoch 277/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2174 - accuracy: 0.9320 - val_loss: 1.3731 - val_accuracy: 0.7698\n",
      "Epoch 278/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2634 - accuracy: 0.9181 - val_loss: 1.5648 - val_accuracy: 0.7766\n",
      "Epoch 279/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1982 - accuracy: 0.9348 - val_loss: 1.3882 - val_accuracy: 0.7583\n",
      "Epoch 280/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2615 - accuracy: 0.9148 - val_loss: 1.3432 - val_accuracy: 0.7617\n",
      "Epoch 281/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2294 - accuracy: 0.9278 - val_loss: 1.4882 - val_accuracy: 0.7835\n",
      "Epoch 282/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2256 - accuracy: 0.9280 - val_loss: 1.4785 - val_accuracy: 0.7388\n",
      "Epoch 283/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2243 - accuracy: 0.9280 - val_loss: 1.3307 - val_accuracy: 0.7640\n",
      "Epoch 284/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9335 - val_loss: 1.8593 - val_accuracy: 0.7239\n",
      "Epoch 285/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2404 - accuracy: 0.9223 - val_loss: 1.4930 - val_accuracy: 0.7663\n",
      "Epoch 286/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2199 - accuracy: 0.9325 - val_loss: 1.3824 - val_accuracy: 0.7297\n",
      "Epoch 287/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2360 - accuracy: 0.9254 - val_loss: 1.3354 - val_accuracy: 0.7560\n",
      "Epoch 288/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1882 - accuracy: 0.9396 - val_loss: 1.4593 - val_accuracy: 0.7572\n",
      "Epoch 289/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2335 - accuracy: 0.9270 - val_loss: 1.4270 - val_accuracy: 0.7595\n",
      "Epoch 290/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.9125 - val_loss: 1.4176 - val_accuracy: 0.7572\n",
      "Epoch 291/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1650 - accuracy: 0.9464 - val_loss: 1.3898 - val_accuracy: 0.7950\n",
      "Epoch 292/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1830 - accuracy: 0.9437 - val_loss: 1.5401 - val_accuracy: 0.7686\n",
      "Epoch 293/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2375 - accuracy: 0.9250 - val_loss: 1.4521 - val_accuracy: 0.7755\n",
      "Epoch 294/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1759 - accuracy: 0.9411 - val_loss: 1.4980 - val_accuracy: 0.7491\n",
      "Epoch 295/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2289 - accuracy: 0.9299 - val_loss: 1.3928 - val_accuracy: 0.7652\n",
      "Epoch 296/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2252 - accuracy: 0.9287 - val_loss: 1.3507 - val_accuracy: 0.7617\n",
      "Epoch 297/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2170 - accuracy: 0.9297 - val_loss: 1.2210 - val_accuracy: 0.7755\n",
      "Epoch 298/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2162 - accuracy: 0.9298 - val_loss: 1.3254 - val_accuracy: 0.7801\n",
      "Epoch 299/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2120 - accuracy: 0.9363 - val_loss: 1.4256 - val_accuracy: 0.7537\n",
      "Epoch 300/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2017 - accuracy: 0.9339 - val_loss: 1.3816 - val_accuracy: 0.7686\n",
      "Epoch 301/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9341 - val_loss: 1.3950 - val_accuracy: 0.7491\n",
      "Epoch 302/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9324 - val_loss: 1.6106 - val_accuracy: 0.7858\n",
      "Epoch 303/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1844 - accuracy: 0.9443 - val_loss: 1.6551 - val_accuracy: 0.7228\n",
      "Epoch 304/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2368 - accuracy: 0.9285 - val_loss: 1.6796 - val_accuracy: 0.7514\n",
      "Epoch 305/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1765 - accuracy: 0.9411 - val_loss: 1.7678 - val_accuracy: 0.7595\n",
      "Epoch 306/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1922 - accuracy: 0.9368 - val_loss: 1.6871 - val_accuracy: 0.7640\n",
      "Epoch 307/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2269 - accuracy: 0.9293 - val_loss: 1.5041 - val_accuracy: 0.7514\n",
      "Epoch 308/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1854 - accuracy: 0.9424 - val_loss: 1.6242 - val_accuracy: 0.7766\n",
      "Epoch 309/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1994 - accuracy: 0.9373 - val_loss: 1.6607 - val_accuracy: 0.7503\n",
      "Epoch 310/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2525 - accuracy: 0.9214 - val_loss: 1.4130 - val_accuracy: 0.7892\n",
      "Epoch 311/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9448 - val_loss: 1.6435 - val_accuracy: 0.7778\n",
      "Epoch 312/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1727 - accuracy: 0.9442 - val_loss: 1.6847 - val_accuracy: 0.7789\n",
      "Epoch 313/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2205 - accuracy: 0.9322 - val_loss: 1.4946 - val_accuracy: 0.7560\n",
      "Epoch 314/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1942 - accuracy: 0.9403 - val_loss: 1.4460 - val_accuracy: 0.7560\n",
      "Epoch 315/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1754 - accuracy: 0.9442 - val_loss: 1.3297 - val_accuracy: 0.7560\n",
      "Epoch 316/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1918 - accuracy: 0.9406 - val_loss: 1.6351 - val_accuracy: 0.7434\n",
      "Epoch 317/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1691 - accuracy: 0.9457 - val_loss: 1.6469 - val_accuracy: 0.7709\n",
      "Epoch 318/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2318 - accuracy: 0.9283 - val_loss: 1.4591 - val_accuracy: 0.7869\n",
      "Epoch 319/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2110 - accuracy: 0.9307 - val_loss: 1.5887 - val_accuracy: 0.7491\n",
      "Epoch 320/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2332 - accuracy: 0.9243 - val_loss: 1.5848 - val_accuracy: 0.7652\n",
      "Epoch 321/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2385 - accuracy: 0.9219 - val_loss: 1.3891 - val_accuracy: 0.7824\n",
      "Epoch 322/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1454 - accuracy: 0.9543 - val_loss: 1.6806 - val_accuracy: 0.7973\n",
      "Epoch 323/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9353 - val_loss: 1.5524 - val_accuracy: 0.7468\n",
      "Epoch 324/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1749 - accuracy: 0.9419 - val_loss: 1.5091 - val_accuracy: 0.7709\n",
      "Epoch 325/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2067 - accuracy: 0.9352 - val_loss: 1.3979 - val_accuracy: 0.7675\n",
      "Epoch 326/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1980 - accuracy: 0.9395 - val_loss: 1.4450 - val_accuracy: 0.7595\n",
      "Epoch 327/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2171 - accuracy: 0.9292 - val_loss: 1.3664 - val_accuracy: 0.7514\n",
      "Epoch 328/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2137 - accuracy: 0.9320 - val_loss: 1.3829 - val_accuracy: 0.7812\n",
      "Epoch 329/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1373 - accuracy: 0.9558 - val_loss: 1.6080 - val_accuracy: 0.7652\n",
      "Epoch 330/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1983 - accuracy: 0.9386 - val_loss: 1.7159 - val_accuracy: 0.7629\n",
      "Epoch 331/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2327 - accuracy: 0.9294 - val_loss: 1.4937 - val_accuracy: 0.7789\n",
      "Epoch 332/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1942 - accuracy: 0.9414 - val_loss: 1.2919 - val_accuracy: 0.7698\n",
      "Epoch 333/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2005 - accuracy: 0.9340 - val_loss: 1.5628 - val_accuracy: 0.7629\n",
      "Epoch 334/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2076 - accuracy: 0.9326 - val_loss: 1.4871 - val_accuracy: 0.7572\n",
      "Epoch 335/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.9466 - val_loss: 1.4002 - val_accuracy: 0.7812\n",
      "Epoch 336/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1905 - accuracy: 0.9434 - val_loss: 1.4264 - val_accuracy: 0.7709\n",
      "Epoch 337/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2385 - accuracy: 0.9234 - val_loss: 1.2707 - val_accuracy: 0.7617\n",
      "Epoch 338/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1957 - accuracy: 0.9396 - val_loss: 1.4768 - val_accuracy: 0.7743\n",
      "Epoch 339/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2480 - accuracy: 0.9236 - val_loss: 1.5614 - val_accuracy: 0.7514\n",
      "Epoch 340/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2196 - accuracy: 0.9332 - val_loss: 1.3417 - val_accuracy: 0.7686\n",
      "Epoch 341/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1772 - accuracy: 0.9419 - val_loss: 1.5765 - val_accuracy: 0.7446\n",
      "Epoch 342/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1708 - accuracy: 0.9469 - val_loss: 1.4710 - val_accuracy: 0.7617\n",
      "Epoch 343/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1795 - accuracy: 0.9452 - val_loss: 1.6592 - val_accuracy: 0.7721\n",
      "Epoch 344/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1406 - accuracy: 0.9536 - val_loss: 1.6932 - val_accuracy: 0.7595\n",
      "Epoch 345/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1884 - accuracy: 0.9428 - val_loss: 1.5660 - val_accuracy: 0.7297\n",
      "Epoch 346/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2541 - accuracy: 0.9242 - val_loss: 1.3383 - val_accuracy: 0.7663\n",
      "Epoch 347/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1533 - accuracy: 0.9520 - val_loss: 1.4677 - val_accuracy: 0.7698\n",
      "Epoch 348/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1832 - accuracy: 0.9400 - val_loss: 1.5275 - val_accuracy: 0.7732\n",
      "Epoch 349/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1626 - accuracy: 0.9516 - val_loss: 1.4718 - val_accuracy: 0.7709\n",
      "Epoch 350/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1863 - accuracy: 0.9419 - val_loss: 1.6430 - val_accuracy: 0.7721\n",
      "Epoch 351/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.9361 - val_loss: 1.4257 - val_accuracy: 0.7766\n",
      "Epoch 352/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1763 - accuracy: 0.9468 - val_loss: 1.8424 - val_accuracy: 0.7526\n",
      "Epoch 353/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2104 - accuracy: 0.9389 - val_loss: 1.3955 - val_accuracy: 0.7732\n",
      "Epoch 354/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2368 - accuracy: 0.9310 - val_loss: 1.9737 - val_accuracy: 0.7125\n",
      "Epoch 355/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2666 - accuracy: 0.9187 - val_loss: 1.3060 - val_accuracy: 0.7881\n",
      "Epoch 356/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1608 - accuracy: 0.9487 - val_loss: 1.6248 - val_accuracy: 0.7675\n",
      "Epoch 357/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1625 - accuracy: 0.9501 - val_loss: 1.7184 - val_accuracy: 0.7663\n",
      "Epoch 358/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1552 - accuracy: 0.9503 - val_loss: 1.5800 - val_accuracy: 0.7892\n",
      "Epoch 359/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1827 - accuracy: 0.9492 - val_loss: 1.7270 - val_accuracy: 0.7801\n",
      "Epoch 360/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1513 - accuracy: 0.9510 - val_loss: 1.4723 - val_accuracy: 0.7595\n",
      "Epoch 361/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1683 - accuracy: 0.9479 - val_loss: 1.5608 - val_accuracy: 0.7560\n",
      "Epoch 362/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1784 - accuracy: 0.9450 - val_loss: 1.7485 - val_accuracy: 0.7640\n",
      "Epoch 363/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9326 - val_loss: 1.5280 - val_accuracy: 0.7617\n",
      "Epoch 364/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1697 - accuracy: 0.9445 - val_loss: 1.5783 - val_accuracy: 0.7709\n",
      "Epoch 365/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1529 - accuracy: 0.9522 - val_loss: 1.4960 - val_accuracy: 0.7652\n",
      "Epoch 366/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1500 - accuracy: 0.9525 - val_loss: 1.5169 - val_accuracy: 0.7675\n",
      "Epoch 367/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1853 - accuracy: 0.9413 - val_loss: 1.3333 - val_accuracy: 0.7801\n",
      "Epoch 368/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1489 - accuracy: 0.9499 - val_loss: 1.5535 - val_accuracy: 0.7743\n",
      "Epoch 369/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1424 - accuracy: 0.9536 - val_loss: 1.5948 - val_accuracy: 0.7812\n",
      "Epoch 370/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9367 - val_loss: 1.5628 - val_accuracy: 0.7549\n",
      "Epoch 371/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1751 - accuracy: 0.9485 - val_loss: 1.4612 - val_accuracy: 0.7801\n",
      "Epoch 372/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1839 - accuracy: 0.9441 - val_loss: 1.5971 - val_accuracy: 0.7617\n",
      "Epoch 373/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1702 - accuracy: 0.9450 - val_loss: 1.7070 - val_accuracy: 0.7812\n",
      "Epoch 374/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.2423 - accuracy: 0.9327 - val_loss: 1.4725 - val_accuracy: 0.7411\n",
      "Epoch 375/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2572 - accuracy: 0.9186 - val_loss: 1.4405 - val_accuracy: 0.7732\n",
      "Epoch 376/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1613 - accuracy: 0.9490 - val_loss: 1.4694 - val_accuracy: 0.7858\n",
      "Epoch 377/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1561 - accuracy: 0.9515 - val_loss: 1.6026 - val_accuracy: 0.7755\n",
      "Epoch 378/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1976 - accuracy: 0.9413 - val_loss: 1.5650 - val_accuracy: 0.7686\n",
      "Epoch 379/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1442 - accuracy: 0.9567 - val_loss: 1.4911 - val_accuracy: 0.7732\n",
      "Epoch 380/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1643 - accuracy: 0.9483 - val_loss: 1.3257 - val_accuracy: 0.7789\n",
      "Epoch 381/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1770 - accuracy: 0.9439 - val_loss: 1.2861 - val_accuracy: 0.7766\n",
      "Epoch 382/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1654 - accuracy: 0.9497 - val_loss: 1.5495 - val_accuracy: 0.7869\n",
      "Epoch 383/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1514 - accuracy: 0.9517 - val_loss: 1.6229 - val_accuracy: 0.7732\n",
      "Epoch 384/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1452 - accuracy: 0.9522 - val_loss: 1.6613 - val_accuracy: 0.7789\n",
      "Epoch 385/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1592 - accuracy: 0.9466 - val_loss: 1.6925 - val_accuracy: 0.7595\n",
      "Epoch 386/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1736 - accuracy: 0.9457 - val_loss: 1.8535 - val_accuracy: 0.7652\n",
      "Epoch 387/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1924 - accuracy: 0.9395 - val_loss: 1.4458 - val_accuracy: 0.7709\n",
      "Epoch 388/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1866 - accuracy: 0.9417 - val_loss: 1.4706 - val_accuracy: 0.7847\n",
      "Epoch 389/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1753 - accuracy: 0.9469 - val_loss: 1.6679 - val_accuracy: 0.7663\n",
      "Epoch 390/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1420 - accuracy: 0.9544 - val_loss: 1.7020 - val_accuracy: 0.7686\n",
      "Epoch 391/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1973 - accuracy: 0.9381 - val_loss: 1.7096 - val_accuracy: 0.7721\n",
      "Epoch 392/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.9456 - val_loss: 1.5973 - val_accuracy: 0.7572\n",
      "Epoch 393/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1589 - accuracy: 0.9518 - val_loss: 1.7625 - val_accuracy: 0.7709\n",
      "Epoch 394/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2275 - accuracy: 0.9348 - val_loss: 1.5047 - val_accuracy: 0.7961\n",
      "Epoch 395/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2010 - accuracy: 0.9414 - val_loss: 1.6821 - val_accuracy: 0.7514\n",
      "Epoch 396/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2084 - accuracy: 0.9378 - val_loss: 1.5365 - val_accuracy: 0.7801\n",
      "Epoch 397/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1719 - accuracy: 0.9445 - val_loss: 1.5826 - val_accuracy: 0.7721\n",
      "Epoch 398/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1510 - accuracy: 0.9525 - val_loss: 1.7208 - val_accuracy: 0.7342\n",
      "Epoch 399/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2116 - accuracy: 0.9345 - val_loss: 1.4495 - val_accuracy: 0.7686\n",
      "Epoch 400/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1539 - accuracy: 0.9499 - val_loss: 1.3295 - val_accuracy: 0.7709\n",
      "Epoch 401/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1534 - accuracy: 0.9529 - val_loss: 1.2689 - val_accuracy: 0.7686\n",
      "Epoch 402/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1566 - accuracy: 0.9485 - val_loss: 1.7497 - val_accuracy: 0.7869\n",
      "Epoch 403/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1400 - accuracy: 0.9559 - val_loss: 1.4526 - val_accuracy: 0.7675\n",
      "Epoch 404/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1471 - accuracy: 0.9515 - val_loss: 1.4503 - val_accuracy: 0.7377\n",
      "Epoch 405/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1928 - accuracy: 0.9389 - val_loss: 1.6539 - val_accuracy: 0.7698\n",
      "Epoch 406/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1521 - accuracy: 0.9529 - val_loss: 1.6915 - val_accuracy: 0.7789\n",
      "Epoch 407/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1557 - accuracy: 0.9506 - val_loss: 1.6755 - val_accuracy: 0.7755\n",
      "Epoch 408/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1796 - accuracy: 0.9432 - val_loss: 1.5664 - val_accuracy: 0.7824\n",
      "Epoch 409/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1880 - accuracy: 0.9417 - val_loss: 1.7856 - val_accuracy: 0.7331\n",
      "Epoch 410/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1697 - accuracy: 0.9476 - val_loss: 1.5438 - val_accuracy: 0.7801\n",
      "Epoch 411/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1598 - accuracy: 0.9496 - val_loss: 1.6160 - val_accuracy: 0.7892\n",
      "Epoch 412/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1553 - accuracy: 0.9497 - val_loss: 1.8966 - val_accuracy: 0.7675\n",
      "Epoch 413/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1895 - accuracy: 0.9413 - val_loss: 1.6921 - val_accuracy: 0.7789\n",
      "Epoch 414/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1790 - accuracy: 0.9437 - val_loss: 1.8721 - val_accuracy: 0.7617\n",
      "Epoch 415/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1414 - accuracy: 0.9546 - val_loss: 1.6758 - val_accuracy: 0.7663\n",
      "Epoch 416/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2536 - accuracy: 0.9313 - val_loss: 1.4451 - val_accuracy: 0.7308\n",
      "Epoch 417/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1590 - accuracy: 0.9496 - val_loss: 1.6228 - val_accuracy: 0.7675\n",
      "Epoch 418/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1857 - accuracy: 0.9456 - val_loss: 1.6930 - val_accuracy: 0.7297\n",
      "Epoch 419/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1460 - accuracy: 0.9539 - val_loss: 1.4706 - val_accuracy: 0.7801\n",
      "Epoch 420/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.9529 - val_loss: 1.8629 - val_accuracy: 0.7869\n",
      "Epoch 421/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1505 - accuracy: 0.9517 - val_loss: 1.7084 - val_accuracy: 0.7835\n",
      "Epoch 422/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1570 - accuracy: 0.9506 - val_loss: 1.5950 - val_accuracy: 0.7743\n",
      "Epoch 423/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2107 - accuracy: 0.9378 - val_loss: 1.6855 - val_accuracy: 0.7514\n",
      "Epoch 424/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1841 - accuracy: 0.9443 - val_loss: 1.3729 - val_accuracy: 0.7629\n",
      "Epoch 425/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1320 - accuracy: 0.9596 - val_loss: 1.8173 - val_accuracy: 0.7789\n",
      "Epoch 426/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1494 - accuracy: 0.9526 - val_loss: 1.4186 - val_accuracy: 0.7709\n",
      "Epoch 427/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1544 - accuracy: 0.9513 - val_loss: 1.6160 - val_accuracy: 0.7595\n",
      "Epoch 428/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1398 - accuracy: 0.9553 - val_loss: 1.9821 - val_accuracy: 0.7640\n",
      "Epoch 429/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1632 - accuracy: 0.9526 - val_loss: 1.7048 - val_accuracy: 0.7732\n",
      "Epoch 430/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9396 - val_loss: 1.6338 - val_accuracy: 0.7675\n",
      "Epoch 431/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1792 - accuracy: 0.9429 - val_loss: 1.6365 - val_accuracy: 0.7835\n",
      "Epoch 432/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1491 - accuracy: 0.9555 - val_loss: 1.8774 - val_accuracy: 0.7640\n",
      "Epoch 433/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1744 - accuracy: 0.9494 - val_loss: 1.4262 - val_accuracy: 0.7698\n",
      "Epoch 434/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2056 - accuracy: 0.9389 - val_loss: 1.5710 - val_accuracy: 0.7755\n",
      "Epoch 435/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1635 - accuracy: 0.9492 - val_loss: 1.5368 - val_accuracy: 0.7549\n",
      "Epoch 436/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1488 - accuracy: 0.9534 - val_loss: 1.6728 - val_accuracy: 0.7709\n",
      "Epoch 437/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1441 - accuracy: 0.9603 - val_loss: 1.8224 - val_accuracy: 0.7583\n",
      "Epoch 438/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1487 - accuracy: 0.9527 - val_loss: 1.7403 - val_accuracy: 0.7686\n",
      "Epoch 439/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1747 - accuracy: 0.9473 - val_loss: 1.6321 - val_accuracy: 0.7595\n",
      "Epoch 440/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1468 - accuracy: 0.9535 - val_loss: 1.5405 - val_accuracy: 0.7629\n",
      "Epoch 441/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2076 - accuracy: 0.9401 - val_loss: 1.5266 - val_accuracy: 0.7537\n",
      "Epoch 442/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1319 - accuracy: 0.9578 - val_loss: 1.6945 - val_accuracy: 0.7766\n",
      "Epoch 443/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1401 - accuracy: 0.9594 - val_loss: 1.8831 - val_accuracy: 0.7847\n",
      "Epoch 444/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1439 - accuracy: 0.9563 - val_loss: 2.0009 - val_accuracy: 0.7686\n",
      "Epoch 445/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1374 - accuracy: 0.9562 - val_loss: 1.6827 - val_accuracy: 0.7766\n",
      "Epoch 446/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2143 - accuracy: 0.9375 - val_loss: 1.5420 - val_accuracy: 0.7904\n",
      "Epoch 447/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1461 - accuracy: 0.9559 - val_loss: 1.5014 - val_accuracy: 0.7789\n",
      "Epoch 448/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1614 - accuracy: 0.9494 - val_loss: 1.4530 - val_accuracy: 0.7812\n",
      "Epoch 449/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1134 - accuracy: 0.9647 - val_loss: 1.8148 - val_accuracy: 0.7961\n",
      "Epoch 450/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1703 - accuracy: 0.9535 - val_loss: 1.6586 - val_accuracy: 0.7503\n",
      "Epoch 451/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1613 - accuracy: 0.9487 - val_loss: 1.9161 - val_accuracy: 0.7721\n",
      "Epoch 452/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1336 - accuracy: 0.9591 - val_loss: 1.8535 - val_accuracy: 0.7629\n",
      "Epoch 453/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2373 - accuracy: 0.9339 - val_loss: 1.6888 - val_accuracy: 0.7721\n",
      "Epoch 454/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1235 - accuracy: 0.9608 - val_loss: 1.7361 - val_accuracy: 0.7606\n",
      "Epoch 455/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1449 - accuracy: 0.9573 - val_loss: 1.6213 - val_accuracy: 0.7904\n",
      "Epoch 456/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1766 - accuracy: 0.9527 - val_loss: 1.5259 - val_accuracy: 0.7709\n",
      "Epoch 457/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1887 - accuracy: 0.9460 - val_loss: 1.6286 - val_accuracy: 0.7766\n",
      "Epoch 458/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1264 - accuracy: 0.9595 - val_loss: 1.9414 - val_accuracy: 0.7617\n",
      "Epoch 459/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1486 - accuracy: 0.9541 - val_loss: 1.8333 - val_accuracy: 0.7847\n",
      "Epoch 460/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1079 - accuracy: 0.9678 - val_loss: 2.0579 - val_accuracy: 0.7869\n",
      "Epoch 461/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1648 - accuracy: 0.9487 - val_loss: 1.8870 - val_accuracy: 0.7583\n",
      "Epoch 462/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1809 - accuracy: 0.9474 - val_loss: 2.0725 - val_accuracy: 0.7434\n",
      "Epoch 463/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1866 - accuracy: 0.9451 - val_loss: 1.8257 - val_accuracy: 0.7789\n",
      "Epoch 464/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1235 - accuracy: 0.9620 - val_loss: 1.8094 - val_accuracy: 0.7560\n",
      "Epoch 465/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1833 - accuracy: 0.9478 - val_loss: 2.0427 - val_accuracy: 0.7755\n",
      "Epoch 466/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1648 - accuracy: 0.9487 - val_loss: 1.7917 - val_accuracy: 0.7721\n",
      "Epoch 467/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1498 - accuracy: 0.9545 - val_loss: 1.7079 - val_accuracy: 0.7812\n",
      "Epoch 468/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1739 - accuracy: 0.9504 - val_loss: 1.9008 - val_accuracy: 0.7423\n",
      "Epoch 469/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2077 - accuracy: 0.9376 - val_loss: 1.5513 - val_accuracy: 0.7824\n",
      "Epoch 470/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1442 - accuracy: 0.9557 - val_loss: 1.4794 - val_accuracy: 0.7881\n",
      "Epoch 471/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1749 - accuracy: 0.9470 - val_loss: 1.4318 - val_accuracy: 0.7892\n",
      "Epoch 472/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1264 - accuracy: 0.9605 - val_loss: 1.5150 - val_accuracy: 0.7881\n",
      "Epoch 473/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1357 - accuracy: 0.9597 - val_loss: 1.5867 - val_accuracy: 0.7732\n",
      "Epoch 474/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1380 - accuracy: 0.9572 - val_loss: 1.7582 - val_accuracy: 0.7640\n",
      "Epoch 475/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1636 - accuracy: 0.9487 - val_loss: 1.5168 - val_accuracy: 0.7709\n",
      "Epoch 476/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1246 - accuracy: 0.9610 - val_loss: 1.7423 - val_accuracy: 0.7652\n",
      "Epoch 477/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1192 - accuracy: 0.9629 - val_loss: 1.8341 - val_accuracy: 0.7755\n",
      "Epoch 478/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1586 - accuracy: 0.9527 - val_loss: 1.6950 - val_accuracy: 0.7572\n",
      "Epoch 479/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1337 - accuracy: 0.9553 - val_loss: 1.9589 - val_accuracy: 0.7721\n",
      "Epoch 480/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1243 - accuracy: 0.9586 - val_loss: 1.9079 - val_accuracy: 0.7617\n",
      "Epoch 481/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2003 - accuracy: 0.9418 - val_loss: 1.6107 - val_accuracy: 0.7721\n",
      "Epoch 482/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1209 - accuracy: 0.9604 - val_loss: 1.6096 - val_accuracy: 0.7743\n",
      "Epoch 483/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1988 - accuracy: 0.9420 - val_loss: 1.5458 - val_accuracy: 0.7743\n",
      "Epoch 484/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1543 - accuracy: 0.9552 - val_loss: 1.4919 - val_accuracy: 0.7400\n",
      "Epoch 485/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1667 - accuracy: 0.9522 - val_loss: 1.8158 - val_accuracy: 0.7595\n",
      "Epoch 486/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1918 - accuracy: 0.9450 - val_loss: 1.5675 - val_accuracy: 0.7824\n",
      "Epoch 487/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2632 - accuracy: 0.9357 - val_loss: 1.4982 - val_accuracy: 0.7148\n",
      "Epoch 488/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1685 - accuracy: 0.9498 - val_loss: 1.3559 - val_accuracy: 0.7652\n",
      "Epoch 489/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1229 - accuracy: 0.9615 - val_loss: 1.6881 - val_accuracy: 0.7732\n",
      "Epoch 490/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1356 - accuracy: 0.9580 - val_loss: 1.6028 - val_accuracy: 0.7629\n",
      "Epoch 491/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1869 - accuracy: 0.9466 - val_loss: 1.5232 - val_accuracy: 0.7686\n",
      "Epoch 492/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1716 - accuracy: 0.9462 - val_loss: 1.3833 - val_accuracy: 0.7595\n",
      "Epoch 493/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1171 - accuracy: 0.9614 - val_loss: 1.4778 - val_accuracy: 0.7755\n",
      "Epoch 494/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1001 - accuracy: 0.9678 - val_loss: 1.5337 - val_accuracy: 0.7686\n",
      "Epoch 495/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1312 - accuracy: 0.9590 - val_loss: 1.6331 - val_accuracy: 0.7721\n",
      "Epoch 496/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1048 - accuracy: 0.9674 - val_loss: 1.5878 - val_accuracy: 0.7743\n",
      "Epoch 497/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1527 - accuracy: 0.9550 - val_loss: 1.5826 - val_accuracy: 0.7732\n",
      "Epoch 498/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1339 - accuracy: 0.9580 - val_loss: 1.5335 - val_accuracy: 0.7743\n",
      "Epoch 499/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2103 - accuracy: 0.9390 - val_loss: 1.3518 - val_accuracy: 0.7698\n",
      "Epoch 500/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1437 - accuracy: 0.9552 - val_loss: 1.4748 - val_accuracy: 0.7858\n",
      "Epoch 501/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1027 - accuracy: 0.9694 - val_loss: 1.6597 - val_accuracy: 0.7675\n",
      "Epoch 502/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1096 - accuracy: 0.9646 - val_loss: 1.6518 - val_accuracy: 0.7927\n",
      "Epoch 503/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1384 - accuracy: 0.9568 - val_loss: 1.7555 - val_accuracy: 0.7468\n",
      "Epoch 504/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1776 - accuracy: 0.9493 - val_loss: 1.5486 - val_accuracy: 0.7663\n",
      "Epoch 505/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1500 - accuracy: 0.9549 - val_loss: 1.6634 - val_accuracy: 0.7595\n",
      "Epoch 506/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1421 - accuracy: 0.9554 - val_loss: 1.5327 - val_accuracy: 0.7927\n",
      "Epoch 507/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1899 - accuracy: 0.9445 - val_loss: 1.5241 - val_accuracy: 0.7732\n",
      "Epoch 508/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1192 - accuracy: 0.9636 - val_loss: 1.6988 - val_accuracy: 0.7560\n",
      "Epoch 509/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1596 - accuracy: 0.9508 - val_loss: 2.0320 - val_accuracy: 0.7595\n",
      "Epoch 510/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1894 - accuracy: 0.9432 - val_loss: 1.8622 - val_accuracy: 0.7468\n",
      "Epoch 511/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1697 - accuracy: 0.9517 - val_loss: 1.8865 - val_accuracy: 0.7560\n",
      "Epoch 512/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1525 - accuracy: 0.9576 - val_loss: 1.9780 - val_accuracy: 0.7526\n",
      "Epoch 513/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1920 - accuracy: 0.9454 - val_loss: 1.6513 - val_accuracy: 0.7732\n",
      "Epoch 514/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9415 - val_loss: 1.5443 - val_accuracy: 0.7698\n",
      "Epoch 515/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1734 - accuracy: 0.9508 - val_loss: 1.4320 - val_accuracy: 0.7824\n",
      "Epoch 516/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0896 - accuracy: 0.9717 - val_loss: 1.7822 - val_accuracy: 0.7686\n",
      "Epoch 517/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1435 - accuracy: 0.9558 - val_loss: 2.0078 - val_accuracy: 0.7652\n",
      "Epoch 518/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1455 - accuracy: 0.9578 - val_loss: 1.7452 - val_accuracy: 0.7583\n",
      "Epoch 519/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1207 - accuracy: 0.9614 - val_loss: 2.4551 - val_accuracy: 0.7182\n",
      "Epoch 520/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1149 - accuracy: 0.9655 - val_loss: 2.1102 - val_accuracy: 0.7583\n",
      "Epoch 521/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1902 - accuracy: 0.9494 - val_loss: 1.9662 - val_accuracy: 0.7503\n",
      "Epoch 522/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1612 - accuracy: 0.9532 - val_loss: 1.8215 - val_accuracy: 0.7583\n",
      "Epoch 523/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1563 - accuracy: 0.9535 - val_loss: 1.9364 - val_accuracy: 0.7629\n",
      "Epoch 524/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1485 - accuracy: 0.9548 - val_loss: 1.5859 - val_accuracy: 0.7743\n",
      "Epoch 525/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1143 - accuracy: 0.9647 - val_loss: 1.7151 - val_accuracy: 0.7881\n",
      "Epoch 526/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0982 - accuracy: 0.9685 - val_loss: 2.0171 - val_accuracy: 0.7766\n",
      "Epoch 527/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1691 - accuracy: 0.9544 - val_loss: 1.7411 - val_accuracy: 0.7205\n",
      "Epoch 528/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1486 - accuracy: 0.9541 - val_loss: 1.4958 - val_accuracy: 0.7572\n",
      "Epoch 529/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1573 - accuracy: 0.9564 - val_loss: 1.5109 - val_accuracy: 0.7686\n",
      "Epoch 530/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1116 - accuracy: 0.9654 - val_loss: 2.1004 - val_accuracy: 0.7927\n",
      "Epoch 531/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1781 - accuracy: 0.9493 - val_loss: 1.5469 - val_accuracy: 0.7789\n",
      "Epoch 532/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1456 - accuracy: 0.9573 - val_loss: 1.9206 - val_accuracy: 0.7675\n",
      "Epoch 533/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1593 - accuracy: 0.9524 - val_loss: 1.8093 - val_accuracy: 0.7892\n",
      "Epoch 534/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1352 - accuracy: 0.9589 - val_loss: 1.5796 - val_accuracy: 0.7892\n",
      "Epoch 535/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1290 - accuracy: 0.9590 - val_loss: 1.8482 - val_accuracy: 0.7377\n",
      "Epoch 536/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1417 - accuracy: 0.9539 - val_loss: 1.7169 - val_accuracy: 0.7617\n",
      "Epoch 537/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1721 - accuracy: 0.9524 - val_loss: 1.5794 - val_accuracy: 0.7514\n",
      "Epoch 538/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1180 - accuracy: 0.9631 - val_loss: 1.8057 - val_accuracy: 0.7652\n",
      "Epoch 539/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1481 - accuracy: 0.9590 - val_loss: 1.9434 - val_accuracy: 0.7709\n",
      "Epoch 540/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1210 - accuracy: 0.9629 - val_loss: 1.5932 - val_accuracy: 0.7824\n",
      "Epoch 541/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1166 - accuracy: 0.9620 - val_loss: 1.9198 - val_accuracy: 0.7583\n",
      "Epoch 542/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1447 - accuracy: 0.9596 - val_loss: 1.7749 - val_accuracy: 0.7640\n",
      "Epoch 543/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1090 - accuracy: 0.9676 - val_loss: 1.9728 - val_accuracy: 0.7847\n",
      "Epoch 544/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0996 - accuracy: 0.9687 - val_loss: 1.8981 - val_accuracy: 0.7801\n",
      "Epoch 545/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1926 - accuracy: 0.9471 - val_loss: 1.7838 - val_accuracy: 0.7503\n",
      "Epoch 546/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2002 - accuracy: 0.9424 - val_loss: 1.9827 - val_accuracy: 0.7629\n",
      "Epoch 547/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1337 - accuracy: 0.9590 - val_loss: 2.0697 - val_accuracy: 0.7583\n",
      "Epoch 548/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1596 - accuracy: 0.9539 - val_loss: 1.7177 - val_accuracy: 0.7377\n",
      "Epoch 549/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1493 - accuracy: 0.9532 - val_loss: 2.1428 - val_accuracy: 0.7526\n",
      "Epoch 550/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1681 - accuracy: 0.9541 - val_loss: 2.0144 - val_accuracy: 0.7537\n",
      "Epoch 551/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1899 - accuracy: 0.9432 - val_loss: 1.7327 - val_accuracy: 0.7411\n",
      "Epoch 552/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1078 - accuracy: 0.9673 - val_loss: 1.6544 - val_accuracy: 0.7824\n",
      "Epoch 553/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1387 - accuracy: 0.9605 - val_loss: 1.8064 - val_accuracy: 0.7675\n",
      "Epoch 554/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1562 - accuracy: 0.9527 - val_loss: 1.5774 - val_accuracy: 0.7743\n",
      "Epoch 555/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1104 - accuracy: 0.9652 - val_loss: 1.8191 - val_accuracy: 0.7847\n",
      "Epoch 556/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1594 - accuracy: 0.9553 - val_loss: 1.8602 - val_accuracy: 0.7423\n",
      "Epoch 557/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1407 - accuracy: 0.9581 - val_loss: 1.7272 - val_accuracy: 0.7778\n",
      "Epoch 558/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1048 - accuracy: 0.9674 - val_loss: 1.7796 - val_accuracy: 0.7812\n",
      "Epoch 559/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1141 - accuracy: 0.9656 - val_loss: 1.8994 - val_accuracy: 0.7847\n",
      "Epoch 560/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1644 - accuracy: 0.9539 - val_loss: 1.8719 - val_accuracy: 0.7709\n",
      "Epoch 561/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1227 - accuracy: 0.9642 - val_loss: 1.9212 - val_accuracy: 0.7572\n",
      "Epoch 562/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1576 - accuracy: 0.9585 - val_loss: 1.6787 - val_accuracy: 0.7663\n",
      "Epoch 563/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1114 - accuracy: 0.9646 - val_loss: 1.7165 - val_accuracy: 0.7652\n",
      "Epoch 564/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1060 - accuracy: 0.9689 - val_loss: 2.1201 - val_accuracy: 0.7629\n",
      "Epoch 565/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1489 - accuracy: 0.9567 - val_loss: 1.8923 - val_accuracy: 0.7400\n",
      "Epoch 566/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2432 - accuracy: 0.9383 - val_loss: 1.6961 - val_accuracy: 0.7468\n",
      "Epoch 567/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1235 - accuracy: 0.9622 - val_loss: 1.6067 - val_accuracy: 0.7526\n",
      "Epoch 568/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1258 - accuracy: 0.9656 - val_loss: 1.8278 - val_accuracy: 0.7801\n",
      "Epoch 569/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1191 - accuracy: 0.9659 - val_loss: 1.8091 - val_accuracy: 0.8007\n",
      "Epoch 570/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0931 - accuracy: 0.9703 - val_loss: 1.8756 - val_accuracy: 0.7617\n",
      "Epoch 571/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1113 - accuracy: 0.9654 - val_loss: 1.7485 - val_accuracy: 0.7675\n",
      "Epoch 572/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1143 - accuracy: 0.9661 - val_loss: 1.9321 - val_accuracy: 0.7686\n",
      "Epoch 573/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1601 - accuracy: 0.9555 - val_loss: 1.6422 - val_accuracy: 0.7709\n",
      "Epoch 574/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1189 - accuracy: 0.9647 - val_loss: 1.6943 - val_accuracy: 0.7766\n",
      "Epoch 575/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1576 - accuracy: 0.9527 - val_loss: 1.8925 - val_accuracy: 0.7491\n",
      "Epoch 576/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2302 - accuracy: 0.9408 - val_loss: 1.5735 - val_accuracy: 0.7766\n",
      "Epoch 577/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1322 - accuracy: 0.9657 - val_loss: 1.6820 - val_accuracy: 0.7755\n",
      "Epoch 578/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1365 - accuracy: 0.9583 - val_loss: 1.9980 - val_accuracy: 0.7743\n",
      "Epoch 579/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9629 - val_loss: 1.7168 - val_accuracy: 0.7652\n",
      "Epoch 580/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1603 - accuracy: 0.9532 - val_loss: 1.9517 - val_accuracy: 0.7526\n",
      "Epoch 581/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1289 - accuracy: 0.9604 - val_loss: 1.9348 - val_accuracy: 0.7835\n",
      "Epoch 582/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1196 - accuracy: 0.9647 - val_loss: 1.7626 - val_accuracy: 0.7652\n",
      "Epoch 583/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0862 - accuracy: 0.9741 - val_loss: 1.7650 - val_accuracy: 0.7995\n",
      "Epoch 584/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1413 - accuracy: 0.9601 - val_loss: 1.9708 - val_accuracy: 0.7698\n",
      "Epoch 585/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1187 - accuracy: 0.9632 - val_loss: 1.7797 - val_accuracy: 0.7892\n",
      "Epoch 586/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.9662 - val_loss: 1.8781 - val_accuracy: 0.7732\n",
      "Epoch 587/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1611 - accuracy: 0.9526 - val_loss: 1.9719 - val_accuracy: 0.7755\n",
      "Epoch 588/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1580 - accuracy: 0.9540 - val_loss: 1.7716 - val_accuracy: 0.7640\n",
      "Epoch 589/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1178 - accuracy: 0.9648 - val_loss: 1.6877 - val_accuracy: 0.7537\n",
      "Epoch 590/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1411 - accuracy: 0.9608 - val_loss: 1.9789 - val_accuracy: 0.7743\n",
      "Epoch 591/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0870 - accuracy: 0.9741 - val_loss: 2.2326 - val_accuracy: 0.7858\n",
      "Epoch 592/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1206 - accuracy: 0.9661 - val_loss: 1.9643 - val_accuracy: 0.7812\n",
      "Epoch 593/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1589 - accuracy: 0.9568 - val_loss: 1.9319 - val_accuracy: 0.7526\n",
      "Epoch 594/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1573 - accuracy: 0.9494 - val_loss: 2.2364 - val_accuracy: 0.7686\n",
      "Epoch 595/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1470 - accuracy: 0.9576 - val_loss: 1.8452 - val_accuracy: 0.7663\n",
      "Epoch 596/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9659 - val_loss: 1.8647 - val_accuracy: 0.7709\n",
      "Epoch 597/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1496 - accuracy: 0.9575 - val_loss: 1.7009 - val_accuracy: 0.7755\n",
      "Epoch 598/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1775 - accuracy: 0.9518 - val_loss: 1.5783 - val_accuracy: 0.7640\n",
      "Epoch 599/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1595 - accuracy: 0.9549 - val_loss: 1.4451 - val_accuracy: 0.7698\n",
      "Epoch 600/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1309 - accuracy: 0.9619 - val_loss: 1.8715 - val_accuracy: 0.7560\n",
      "Epoch 601/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1464 - accuracy: 0.9594 - val_loss: 1.6609 - val_accuracy: 0.7675\n",
      "Epoch 602/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1653 - accuracy: 0.9525 - val_loss: 1.6426 - val_accuracy: 0.7480\n",
      "Epoch 603/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0892 - accuracy: 0.9730 - val_loss: 1.8707 - val_accuracy: 0.7778\n",
      "Epoch 604/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0772 - accuracy: 0.9778 - val_loss: 1.8905 - val_accuracy: 0.7766\n",
      "Epoch 605/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1115 - accuracy: 0.9690 - val_loss: 1.7709 - val_accuracy: 0.7732\n",
      "Epoch 606/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2136 - accuracy: 0.9470 - val_loss: 1.6771 - val_accuracy: 0.7423\n",
      "Epoch 607/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1993 - accuracy: 0.9442 - val_loss: 1.7089 - val_accuracy: 0.7434\n",
      "Epoch 608/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1165 - accuracy: 0.9647 - val_loss: 1.7425 - val_accuracy: 0.7698\n",
      "Epoch 609/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9777 - val_loss: 1.5630 - val_accuracy: 0.7778\n",
      "Epoch 610/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1091 - accuracy: 0.9679 - val_loss: 1.8392 - val_accuracy: 0.7652\n",
      "Epoch 611/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0866 - accuracy: 0.9712 - val_loss: 1.9069 - val_accuracy: 0.7778\n",
      "Epoch 612/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1054 - accuracy: 0.9694 - val_loss: 1.7930 - val_accuracy: 0.7812\n",
      "Epoch 613/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9608 - val_loss: 1.7452 - val_accuracy: 0.7595\n",
      "Epoch 614/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0994 - accuracy: 0.9676 - val_loss: 1.9057 - val_accuracy: 0.7721\n",
      "Epoch 615/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.9599 - val_loss: 2.0904 - val_accuracy: 0.7709\n",
      "Epoch 616/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1689 - accuracy: 0.9538 - val_loss: 1.8296 - val_accuracy: 0.7629\n",
      "Epoch 617/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1267 - accuracy: 0.9634 - val_loss: 1.9577 - val_accuracy: 0.7721\n",
      "Epoch 618/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1141 - accuracy: 0.9710 - val_loss: 1.9652 - val_accuracy: 0.7629\n",
      "Epoch 619/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9596 - val_loss: 1.9531 - val_accuracy: 0.7537\n",
      "Epoch 620/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1683 - accuracy: 0.9550 - val_loss: 1.7616 - val_accuracy: 0.7721\n",
      "Epoch 621/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1913 - accuracy: 0.9464 - val_loss: 1.4617 - val_accuracy: 0.7858\n",
      "Epoch 622/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1054 - accuracy: 0.9683 - val_loss: 1.5720 - val_accuracy: 0.7640\n",
      "Epoch 623/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9713 - val_loss: 1.6205 - val_accuracy: 0.7411\n",
      "Epoch 624/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1249 - accuracy: 0.9633 - val_loss: 1.7122 - val_accuracy: 0.7961\n",
      "Epoch 625/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1347 - accuracy: 0.9625 - val_loss: 1.6119 - val_accuracy: 0.7560\n",
      "Epoch 626/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 0.9636 - val_loss: 1.9511 - val_accuracy: 0.7732\n",
      "Epoch 627/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1195 - accuracy: 0.9678 - val_loss: 2.0261 - val_accuracy: 0.7457\n",
      "Epoch 628/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2300 - accuracy: 0.9380 - val_loss: 1.7812 - val_accuracy: 0.7572\n",
      "Epoch 629/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1422 - accuracy: 0.9617 - val_loss: 1.7081 - val_accuracy: 0.7675\n",
      "Epoch 630/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1716 - accuracy: 0.9521 - val_loss: 1.6362 - val_accuracy: 0.7709\n",
      "Epoch 631/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.9688 - val_loss: 1.8773 - val_accuracy: 0.7640\n",
      "Epoch 632/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1246 - accuracy: 0.9642 - val_loss: 1.6973 - val_accuracy: 0.7835\n",
      "Epoch 633/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1837 - accuracy: 0.9479 - val_loss: 1.5887 - val_accuracy: 0.7789\n",
      "Epoch 634/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0920 - accuracy: 0.9734 - val_loss: 1.7159 - val_accuracy: 0.7709\n",
      "Epoch 635/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9704 - val_loss: 1.9090 - val_accuracy: 0.7801\n",
      "Epoch 636/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0928 - accuracy: 0.9732 - val_loss: 2.1474 - val_accuracy: 0.7251\n",
      "Epoch 637/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1408 - accuracy: 0.9604 - val_loss: 1.8521 - val_accuracy: 0.7789\n",
      "Epoch 638/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9741 - val_loss: 2.0179 - val_accuracy: 0.7743\n",
      "Epoch 639/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1058 - accuracy: 0.9689 - val_loss: 1.9260 - val_accuracy: 0.7755\n",
      "Epoch 640/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1583 - accuracy: 0.9572 - val_loss: 1.7864 - val_accuracy: 0.7789\n",
      "Epoch 641/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1432 - accuracy: 0.9605 - val_loss: 2.0912 - val_accuracy: 0.7365\n",
      "Epoch 642/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9439 - val_loss: 1.7952 - val_accuracy: 0.7640\n",
      "Epoch 643/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1118 - accuracy: 0.9647 - val_loss: 1.6600 - val_accuracy: 0.7755\n",
      "Epoch 644/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1245 - accuracy: 0.9637 - val_loss: 1.9236 - val_accuracy: 0.7743\n",
      "Epoch 645/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0991 - accuracy: 0.9731 - val_loss: 1.5519 - val_accuracy: 0.7617\n",
      "Epoch 646/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0981 - accuracy: 0.9717 - val_loss: 1.8874 - val_accuracy: 0.7411\n",
      "Epoch 647/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1372 - accuracy: 0.9599 - val_loss: 2.0115 - val_accuracy: 0.7686\n",
      "Epoch 648/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1239 - accuracy: 0.9648 - val_loss: 2.1495 - val_accuracy: 0.7606\n",
      "Epoch 649/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1698 - accuracy: 0.9492 - val_loss: 1.6956 - val_accuracy: 0.7824\n",
      "Epoch 650/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0914 - accuracy: 0.9727 - val_loss: 1.9434 - val_accuracy: 0.7698\n",
      "Epoch 651/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1730 - accuracy: 0.9536 - val_loss: 1.4268 - val_accuracy: 0.7583\n",
      "Epoch 652/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1105 - accuracy: 0.9670 - val_loss: 1.7846 - val_accuracy: 0.7789\n",
      "Epoch 653/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1395 - accuracy: 0.9622 - val_loss: 1.9482 - val_accuracy: 0.7663\n",
      "Epoch 654/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1192 - accuracy: 0.9684 - val_loss: 1.9496 - val_accuracy: 0.7789\n",
      "Epoch 655/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1189 - accuracy: 0.9637 - val_loss: 2.1107 - val_accuracy: 0.7595\n",
      "Epoch 656/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1271 - accuracy: 0.9648 - val_loss: 1.7135 - val_accuracy: 0.7743\n",
      "Epoch 657/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1567 - accuracy: 0.9587 - val_loss: 1.4442 - val_accuracy: 0.7400\n",
      "Epoch 658/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1180 - accuracy: 0.9642 - val_loss: 1.7160 - val_accuracy: 0.7858\n",
      "Epoch 659/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1124 - accuracy: 0.9702 - val_loss: 1.7984 - val_accuracy: 0.7617\n",
      "Epoch 660/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1054 - accuracy: 0.9724 - val_loss: 1.9867 - val_accuracy: 0.7583\n",
      "Epoch 661/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1460 - accuracy: 0.9576 - val_loss: 2.0209 - val_accuracy: 0.7583\n",
      "Epoch 662/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0827 - accuracy: 0.9771 - val_loss: 1.7380 - val_accuracy: 0.7743\n",
      "Epoch 663/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.2005 - accuracy: 0.9432 - val_loss: 1.9715 - val_accuracy: 0.7629\n",
      "Epoch 664/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1005 - accuracy: 0.9712 - val_loss: 1.8781 - val_accuracy: 0.7560\n",
      "Epoch 665/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1421 - accuracy: 0.9648 - val_loss: 1.9210 - val_accuracy: 0.7549\n",
      "Epoch 666/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0854 - accuracy: 0.9744 - val_loss: 1.9576 - val_accuracy: 0.7847\n",
      "Epoch 667/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0769 - accuracy: 0.9795 - val_loss: 2.4276 - val_accuracy: 0.7652\n",
      "Epoch 668/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1355 - accuracy: 0.9639 - val_loss: 2.0245 - val_accuracy: 0.7721\n",
      "Epoch 669/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1247 - accuracy: 0.9627 - val_loss: 1.9696 - val_accuracy: 0.7698\n",
      "Epoch 670/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1650 - accuracy: 0.9567 - val_loss: 1.7893 - val_accuracy: 0.7698\n",
      "Epoch 671/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1305 - accuracy: 0.9648 - val_loss: 1.5450 - val_accuracy: 0.7721\n",
      "Epoch 672/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1238 - accuracy: 0.9645 - val_loss: 1.7722 - val_accuracy: 0.7640\n",
      "Epoch 673/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0833 - accuracy: 0.9758 - val_loss: 1.7995 - val_accuracy: 0.7732\n",
      "Epoch 674/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0803 - accuracy: 0.9769 - val_loss: 1.7862 - val_accuracy: 0.7743\n",
      "Epoch 675/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0967 - accuracy: 0.9726 - val_loss: 1.9240 - val_accuracy: 0.7732\n",
      "Epoch 676/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1107 - accuracy: 0.9703 - val_loss: 1.9887 - val_accuracy: 0.7801\n",
      "Epoch 677/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1933 - accuracy: 0.9488 - val_loss: 1.7935 - val_accuracy: 0.7560\n",
      "Epoch 678/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1118 - accuracy: 0.9668 - val_loss: 1.9235 - val_accuracy: 0.7766\n",
      "Epoch 679/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0968 - accuracy: 0.9710 - val_loss: 1.9601 - val_accuracy: 0.7686\n",
      "Epoch 680/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1324 - accuracy: 0.9590 - val_loss: 1.7100 - val_accuracy: 0.7686\n",
      "Epoch 681/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1669 - accuracy: 0.9553 - val_loss: 1.7740 - val_accuracy: 0.7503\n",
      "Epoch 682/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1775 - accuracy: 0.9545 - val_loss: 1.9119 - val_accuracy: 0.7686\n",
      "Epoch 683/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1581 - accuracy: 0.9590 - val_loss: 1.5352 - val_accuracy: 0.7743\n",
      "Epoch 684/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1806 - accuracy: 0.9513 - val_loss: 1.8079 - val_accuracy: 0.7629\n",
      "Epoch 685/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0989 - accuracy: 0.9712 - val_loss: 1.8950 - val_accuracy: 0.7629\n",
      "Epoch 686/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1140 - accuracy: 0.9717 - val_loss: 2.2008 - val_accuracy: 0.7640\n",
      "Epoch 687/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1066 - accuracy: 0.9690 - val_loss: 2.3570 - val_accuracy: 0.7698\n",
      "Epoch 688/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1210 - accuracy: 0.9682 - val_loss: 2.0068 - val_accuracy: 0.7698\n",
      "Epoch 689/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0849 - accuracy: 0.9781 - val_loss: 1.9321 - val_accuracy: 0.7572\n",
      "Epoch 690/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1785 - accuracy: 0.9513 - val_loss: 1.9024 - val_accuracy: 0.7732\n",
      "Epoch 691/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1098 - accuracy: 0.9674 - val_loss: 2.0374 - val_accuracy: 0.7629\n",
      "Epoch 692/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1109 - accuracy: 0.9682 - val_loss: 1.7820 - val_accuracy: 0.7847\n",
      "Epoch 693/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1044 - accuracy: 0.9687 - val_loss: 2.2708 - val_accuracy: 0.7732\n",
      "Epoch 694/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1418 - accuracy: 0.9604 - val_loss: 1.9323 - val_accuracy: 0.7617\n",
      "Epoch 695/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1002 - accuracy: 0.9703 - val_loss: 2.3329 - val_accuracy: 0.7629\n",
      "Epoch 696/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1439 - accuracy: 0.9639 - val_loss: 2.0629 - val_accuracy: 0.7755\n",
      "Epoch 697/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1459 - accuracy: 0.9585 - val_loss: 2.3165 - val_accuracy: 0.7652\n",
      "Epoch 698/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1472 - accuracy: 0.9600 - val_loss: 1.9990 - val_accuracy: 0.7686\n",
      "Epoch 699/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.9469 - val_loss: 1.7859 - val_accuracy: 0.7617\n",
      "Epoch 700/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1012 - accuracy: 0.9703 - val_loss: 2.0309 - val_accuracy: 0.7789\n",
      "Epoch 701/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9673 - val_loss: 1.9327 - val_accuracy: 0.7709\n",
      "Epoch 702/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0753 - accuracy: 0.9785 - val_loss: 2.1497 - val_accuracy: 0.7652\n",
      "Epoch 703/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0934 - accuracy: 0.9716 - val_loss: 1.9635 - val_accuracy: 0.7709\n",
      "Epoch 704/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1494 - accuracy: 0.9625 - val_loss: 1.8656 - val_accuracy: 0.7755\n",
      "Epoch 705/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0981 - accuracy: 0.9703 - val_loss: 1.7024 - val_accuracy: 0.7812\n",
      "Epoch 706/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.9722 - val_loss: 2.4191 - val_accuracy: 0.7778\n",
      "Epoch 707/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1132 - accuracy: 0.9662 - val_loss: 1.8699 - val_accuracy: 0.7824\n",
      "Epoch 708/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0936 - accuracy: 0.9713 - val_loss: 1.9638 - val_accuracy: 0.7640\n",
      "Epoch 709/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1265 - accuracy: 0.9645 - val_loss: 1.9699 - val_accuracy: 0.7835\n",
      "Epoch 710/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1582 - accuracy: 0.9601 - val_loss: 2.1484 - val_accuracy: 0.6827\n",
      "Epoch 711/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1796 - accuracy: 0.9503 - val_loss: 1.8808 - val_accuracy: 0.7801\n",
      "Epoch 712/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1197 - accuracy: 0.9704 - val_loss: 2.0203 - val_accuracy: 0.7583\n",
      "Epoch 713/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0794 - accuracy: 0.9746 - val_loss: 2.0437 - val_accuracy: 0.7743\n",
      "Epoch 714/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.9796 - val_loss: 2.0044 - val_accuracy: 0.7743\n",
      "Epoch 715/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0958 - accuracy: 0.9736 - val_loss: 2.1025 - val_accuracy: 0.7709\n",
      "Epoch 716/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0890 - accuracy: 0.9748 - val_loss: 2.0775 - val_accuracy: 0.7835\n",
      "Epoch 717/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1581 - accuracy: 0.9569 - val_loss: 2.2216 - val_accuracy: 0.7755\n",
      "Epoch 718/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1282 - accuracy: 0.9622 - val_loss: 2.2732 - val_accuracy: 0.7721\n",
      "Epoch 719/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0971 - accuracy: 0.9725 - val_loss: 1.9829 - val_accuracy: 0.7789\n",
      "Epoch 720/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1168 - accuracy: 0.9671 - val_loss: 2.0248 - val_accuracy: 0.7617\n",
      "Epoch 721/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1837 - accuracy: 0.9484 - val_loss: 1.9254 - val_accuracy: 0.7583\n",
      "Epoch 722/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1015 - accuracy: 0.9690 - val_loss: 1.9529 - val_accuracy: 0.7766\n",
      "Epoch 723/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1500 - accuracy: 0.9582 - val_loss: 1.7392 - val_accuracy: 0.7652\n",
      "Epoch 724/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1297 - accuracy: 0.9634 - val_loss: 1.9062 - val_accuracy: 0.7675\n",
      "Epoch 725/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1931 - accuracy: 0.9516 - val_loss: 1.8265 - val_accuracy: 0.7537\n",
      "Epoch 726/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0983 - accuracy: 0.9710 - val_loss: 1.8267 - val_accuracy: 0.7824\n",
      "Epoch 727/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0729 - accuracy: 0.9797 - val_loss: 2.0940 - val_accuracy: 0.7824\n",
      "Epoch 728/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0986 - accuracy: 0.9708 - val_loss: 1.8777 - val_accuracy: 0.7812\n",
      "Epoch 729/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0894 - accuracy: 0.9749 - val_loss: 1.8457 - val_accuracy: 0.7675\n",
      "Epoch 730/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1456 - accuracy: 0.9631 - val_loss: 2.0195 - val_accuracy: 0.7835\n",
      "Epoch 731/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0789 - accuracy: 0.9777 - val_loss: 1.8894 - val_accuracy: 0.7732\n",
      "Epoch 732/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1712 - accuracy: 0.9569 - val_loss: 2.3948 - val_accuracy: 0.7572\n",
      "Epoch 733/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1163 - accuracy: 0.9669 - val_loss: 2.0078 - val_accuracy: 0.7766\n",
      "Epoch 734/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0894 - accuracy: 0.9734 - val_loss: 2.1718 - val_accuracy: 0.7709\n",
      "Epoch 735/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9795 - val_loss: 2.1831 - val_accuracy: 0.7766\n",
      "Epoch 736/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1062 - accuracy: 0.9724 - val_loss: 2.0408 - val_accuracy: 0.7869\n",
      "Epoch 737/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1288 - accuracy: 0.9647 - val_loss: 1.9016 - val_accuracy: 0.7743\n",
      "Epoch 738/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 0.9671 - val_loss: 2.4554 - val_accuracy: 0.7446\n",
      "Epoch 739/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9594 - val_loss: 1.9675 - val_accuracy: 0.7583\n",
      "Epoch 740/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1415 - accuracy: 0.9605 - val_loss: 2.1754 - val_accuracy: 0.7721\n",
      "Epoch 741/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9786 - val_loss: 2.2475 - val_accuracy: 0.7743\n",
      "Epoch 742/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1061 - accuracy: 0.9690 - val_loss: 2.4547 - val_accuracy: 0.7709\n",
      "Epoch 743/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0945 - accuracy: 0.9746 - val_loss: 2.4789 - val_accuracy: 0.7560\n",
      "Epoch 744/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1249 - accuracy: 0.9690 - val_loss: 2.1622 - val_accuracy: 0.7721\n",
      "Epoch 745/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.9654 - val_loss: 2.1145 - val_accuracy: 0.7686\n",
      "Epoch 746/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0831 - accuracy: 0.9732 - val_loss: 2.1482 - val_accuracy: 0.7709\n",
      "Epoch 747/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1058 - accuracy: 0.9703 - val_loss: 1.9944 - val_accuracy: 0.7812\n",
      "Epoch 748/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1112 - accuracy: 0.9666 - val_loss: 2.2453 - val_accuracy: 0.7411\n",
      "Epoch 749/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1237 - accuracy: 0.9659 - val_loss: 2.0544 - val_accuracy: 0.7824\n",
      "Epoch 750/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1312 - accuracy: 0.9620 - val_loss: 2.2482 - val_accuracy: 0.7812\n",
      "Epoch 751/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.9606 - val_loss: 1.8273 - val_accuracy: 0.7503\n",
      "Epoch 752/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.2131 - accuracy: 0.9433 - val_loss: 2.0552 - val_accuracy: 0.7686\n",
      "Epoch 753/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1661 - accuracy: 0.9564 - val_loss: 1.9660 - val_accuracy: 0.7560\n",
      "Epoch 754/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.9638 - val_loss: 2.0504 - val_accuracy: 0.7686\n",
      "Epoch 755/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.9809 - val_loss: 2.1768 - val_accuracy: 0.7595\n",
      "Epoch 756/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1125 - accuracy: 0.9697 - val_loss: 2.1046 - val_accuracy: 0.7721\n",
      "Epoch 757/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1116 - accuracy: 0.9664 - val_loss: 1.8880 - val_accuracy: 0.7686\n",
      "Epoch 758/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0735 - accuracy: 0.9783 - val_loss: 2.0805 - val_accuracy: 0.7801\n",
      "Epoch 759/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1365 - accuracy: 0.9665 - val_loss: 2.0514 - val_accuracy: 0.7457\n",
      "Epoch 760/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9634 - val_loss: 2.2519 - val_accuracy: 0.7778\n",
      "Epoch 761/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.9689 - val_loss: 2.1273 - val_accuracy: 0.7675\n",
      "Epoch 762/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 0.9808 - val_loss: 2.0830 - val_accuracy: 0.7847\n",
      "Epoch 763/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1202 - accuracy: 0.9668 - val_loss: 2.3837 - val_accuracy: 0.7595\n",
      "Epoch 764/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0765 - accuracy: 0.9794 - val_loss: 2.2829 - val_accuracy: 0.7847\n",
      "Epoch 765/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0743 - accuracy: 0.9806 - val_loss: 2.1471 - val_accuracy: 0.7675\n",
      "Epoch 766/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9604 - val_loss: 1.9356 - val_accuracy: 0.7686\n",
      "Epoch 767/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1660 - accuracy: 0.9559 - val_loss: 1.9114 - val_accuracy: 0.7869\n",
      "Epoch 768/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1566 - accuracy: 0.9589 - val_loss: 2.3367 - val_accuracy: 0.7572\n",
      "Epoch 769/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.9553 - val_loss: 2.1125 - val_accuracy: 0.7377\n",
      "Epoch 770/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1028 - accuracy: 0.9731 - val_loss: 1.7441 - val_accuracy: 0.7904\n",
      "Epoch 771/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1124 - accuracy: 0.9699 - val_loss: 1.9568 - val_accuracy: 0.7766\n",
      "Epoch 772/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0833 - accuracy: 0.9776 - val_loss: 2.0938 - val_accuracy: 0.7766\n",
      "Epoch 773/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0816 - accuracy: 0.9762 - val_loss: 2.1036 - val_accuracy: 0.7789\n",
      "Epoch 774/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1065 - accuracy: 0.9701 - val_loss: 1.9630 - val_accuracy: 0.7835\n",
      "Epoch 775/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9758 - val_loss: 1.9299 - val_accuracy: 0.7766\n",
      "Epoch 776/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0767 - accuracy: 0.9783 - val_loss: 2.2150 - val_accuracy: 0.7732\n",
      "Epoch 777/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1655 - accuracy: 0.9563 - val_loss: 2.0730 - val_accuracy: 0.7755\n",
      "Epoch 778/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0922 - accuracy: 0.9729 - val_loss: 2.0423 - val_accuracy: 0.7858\n",
      "Epoch 779/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1548 - accuracy: 0.9605 - val_loss: 2.1236 - val_accuracy: 0.7629\n",
      "Epoch 780/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0865 - accuracy: 0.9778 - val_loss: 2.3315 - val_accuracy: 0.7858\n",
      "Epoch 781/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0919 - accuracy: 0.9775 - val_loss: 2.0875 - val_accuracy: 0.7801\n",
      "Epoch 782/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1584 - accuracy: 0.9595 - val_loss: 2.1311 - val_accuracy: 0.7308\n",
      "Epoch 783/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1816 - accuracy: 0.9518 - val_loss: 2.0350 - val_accuracy: 0.7446\n",
      "Epoch 784/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1765 - accuracy: 0.9518 - val_loss: 2.0923 - val_accuracy: 0.7526\n",
      "Epoch 785/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0785 - accuracy: 0.9785 - val_loss: 2.2043 - val_accuracy: 0.7709\n",
      "Epoch 786/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9772 - val_loss: 2.1580 - val_accuracy: 0.7732\n",
      "Epoch 787/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0723 - accuracy: 0.9818 - val_loss: 2.6033 - val_accuracy: 0.7537\n",
      "Epoch 788/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9659 - val_loss: 2.2630 - val_accuracy: 0.7595\n",
      "Epoch 789/800\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.1124 - accuracy: 0.9668 - val_loss: 2.2260 - val_accuracy: 0.7663\n",
      "Epoch 790/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0909 - accuracy: 0.9738 - val_loss: 2.1752 - val_accuracy: 0.7606\n",
      "Epoch 791/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1414 - accuracy: 0.9610 - val_loss: 2.5159 - val_accuracy: 0.7617\n",
      "Epoch 792/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0958 - accuracy: 0.9750 - val_loss: 2.2781 - val_accuracy: 0.7881\n",
      "Epoch 793/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1184 - accuracy: 0.9699 - val_loss: 2.0628 - val_accuracy: 0.7686\n",
      "Epoch 794/800\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.1033 - accuracy: 0.9726 - val_loss: 2.2138 - val_accuracy: 0.7675\n",
      "Epoch 795/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1290 - accuracy: 0.9641 - val_loss: 1.9740 - val_accuracy: 0.7468\n",
      "Epoch 796/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0965 - accuracy: 0.9738 - val_loss: 1.9711 - val_accuracy: 0.7743\n",
      "Epoch 797/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1706 - accuracy: 0.9552 - val_loss: 2.4897 - val_accuracy: 0.7331\n",
      "Epoch 798/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1538 - accuracy: 0.9561 - val_loss: 1.9865 - val_accuracy: 0.7400\n",
      "Epoch 799/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1007 - accuracy: 0.9736 - val_loss: 2.0091 - val_accuracy: 0.7709\n",
      "Epoch 800/800\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.9729 - val_loss: 2.3444 - val_accuracy: 0.7342\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "callbacks=[tensorboard_callback]\n",
    "\n",
    "history = model.fit(train_data,one_hot_train , epochs=800, batch_size=64, validation_data=(test_data, one_hot_test), )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Datasets/Classifiers/speech/mlp\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./Datasets/Classifiers/speech/mlp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('./Datasets/Classifiers/speech/mlp')\n",
    "test_data = dataset['x_test']\n",
    "test_labels = [int(x) for x in dataset['y_test']]\n",
    "\n",
    "predictions = model.predict(test_data)\n",
    "predicted_categories = np.argmax(predictions, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Prediction')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(test_labels, predicted_categories)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.xlabel('Ground truth')\n",
    "plt.ylabel('Prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.78      0.81        96\n",
      "           1       0.78      0.69      0.73        42\n",
      "           2       0.57      0.59      0.58       100\n",
      "           3       0.54      0.56      0.55        90\n",
      "           4       0.79      0.76      0.78       106\n",
      "           5       0.89      0.82      0.85       105\n",
      "           6       0.84      0.82      0.83        33\n",
      "           7       0.78      0.90      0.84       104\n",
      "           8       0.74      0.87      0.80       100\n",
      "           9       0.65      0.55      0.59        97\n",
      "\n",
      "    accuracy                           0.73       873\n",
      "   macro avg       0.74      0.73      0.74       873\n",
      "weighted avg       0.74      0.73      0.73       873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, predicted_categories))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import keras.models\n",
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.io import wavfile as wav\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "def energy(input):\n",
    "    return np.sum((input*1.0)**2, keepdims=True)\n",
    "\n",
    "def feats_spectrogram(input, rate=2000, tsize=10):\n",
    "    trimmed_input = feats_temporal(input, rate)\n",
    "    X = librosa.stft(y=trimmed_input)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    return Xdb.flatten()\n",
    "\n",
    "\n",
    "def feats_mel(input, rate=2000, tsize=10):\n",
    "    trimmed_input = feats_temporal(input, rate)\n",
    "    X = librosa.feature.melspectrogram(y=trimmed_input, sr=rate)\n",
    "    S_DB = librosa.power_to_db(X, ref=np.max)\n",
    "    return S_DB.reshape(S_DB.shape[0] * S_DB.shape[1])\n",
    "\n",
    "\n",
    "def feats_mfcc(input, rate=2000, tsize=10):\n",
    "    trimmed_input = feats_temporal(input, rate)\n",
    "    X = librosa.feature.mfcc(y=trimmed_input, sr=rate)\n",
    "    return X.reshape(X.shape[0] * X.shape[1])\n",
    "\n",
    "\n",
    "def feats_temporal(input, size=2000):\n",
    "    # Remove any values exceeding the given limit\n",
    "    output = input[0:min(size, input.shape[0])]\n",
    "    # Add null values (padding) in order to reach the requested size\n",
    "    output = np.concatenate((output, np.zeros(size-output.shape[0])))\n",
    "    return output\n",
    "\n",
    "def duration(input):\n",
    "    return np.array(input.shape)\n",
    "\n",
    "def get_features(input, filename):\n",
    "    try:\n",
    "        return np.concatenate((energy(input), duration(input), feats_spectrogram(input, 2000), feats_mel(input, 2000), feats_mfcc(input, 2000)))\n",
    "    except Exception as e:\n",
    "        print('Christian')\n",
    "        print(e)\n",
    "\n",
    "\n",
    "\n",
    "def make_classification(sound_path):\n",
    "  #Load classifier\n",
    "  with open('./Datasets/Classifiers/speech/svm1.pickle','rb') as f:\n",
    "    svm_classifier = pickle.load(f)\n",
    "  model = keras.models.load_model('./Datasets/Classifiers/speech/mlp')\n",
    "\n",
    "  #Load sound\n",
    "  _, signal = wav.read(sound_path)\n",
    "  if len(signal.shape) == 2:\n",
    "      signal = np.asarray([x[0] for x in signal])\n",
    "  #Feature extraction\n",
    "  feats = get_features(signal, sound_path)\n",
    "\n",
    "  #classes\n",
    "  classes = ['Air conditioner','Car horn', 'Children playing', 'Dog bark', 'Drilling', 'Engine idling', 'Gun shot', 'Jackhammer', 'Siren', 'Street music']\n",
    "  #Result \n",
    "  res_svm = svm_classifier.predict([feats])\n",
    "  res_mlp = model.predict([feats])\n",
    "  index = np.argmax(res_mlp)\n",
    "  #Print prediction\n",
    "  print(f'The predicted class of the audio by svm is: {classes[int(res_svm[0])]}')\n",
    "  print(f'The predicted class of the audio by mlp is: {classes[index]}')\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3']\n",
      "The predicted class of the audio is: Dog bark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ruben\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=2000\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#https://pixabay.com/sound-effects/search/dog 20barking/\n",
    "# make_classification('./dog_barking.wav')\n",
    "# make_classification('./jackhammer.wav')\n",
    "make_classification('./car-idle.wav')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e850eec08e9669c52e782ee28b71a07544c9e38f5af88e96f29f06e82864309f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
